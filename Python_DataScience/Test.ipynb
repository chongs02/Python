{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신은총 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1)\n",
    "np.arange(0,5,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5],\n",
       "       [ 6,  7,  8,  9, 10]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2)\n",
    "np.arange(1,11).reshape(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3)\n",
    "np.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4)\n",
    "np.ones((4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  3,  5,  7],\n",
       "       [ 9, 11, 13, 15],\n",
       "       [17, 19, 21, 23]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(1,24,2).reshape(3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>지역</th>\n",
       "      <th>2015</th>\n",
       "      <th>2010</th>\n",
       "      <th>2005</th>\n",
       "      <th>2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>서울</th>\n",
       "      <td>수도권</td>\n",
       "      <td>9904312</td>\n",
       "      <td>9631482</td>\n",
       "      <td>9762546</td>\n",
       "      <td>9853972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>부산</th>\n",
       "      <td>경상권</td>\n",
       "      <td>3448737</td>\n",
       "      <td>3393191</td>\n",
       "      <td>3512547</td>\n",
       "      <td>3655437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>인천</th>\n",
       "      <td>수도권</td>\n",
       "      <td>2890451</td>\n",
       "      <td>2632035</td>\n",
       "      <td>2517680</td>\n",
       "      <td>2466338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>대구</th>\n",
       "      <td>경상권</td>\n",
       "      <td>2466052</td>\n",
       "      <td>2431774</td>\n",
       "      <td>2456016</td>\n",
       "      <td>2473990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     지역     2015     2010     2005     2000\n",
       "서울  수도권  9904312  9631482  9762546  9853972\n",
       "부산  경상권  3448737  3393191  3512547  3655437\n",
       "인천  수도권  2890451  2632035  2517680  2466338\n",
       "대구  경상권  2466052  2431774  2456016  2473990"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.precision\", 4)\n",
    "\n",
    "data = {\n",
    "    \"2015\": [9904312, 3448737, 2890451, 2466052],\n",
    "    \"2010\": [9631482, 3393191, 2632035, 2431774],\n",
    "    \"2005\": [9762546, 3512547, 2517680, 2456016],\n",
    "    \"2000\": [9853972, 3655437, 2466338, 2473990],\n",
    "    \"지역\": [\"수도권\", \"경상권\", \"수도권\", \"경상권\"]\n",
    "}\n",
    "columns = [\"지역\", \"2015\", \"2010\", \"2005\", \"2000\"]\n",
    "index = [\"서울\", \"부산\", \"인천\", \"대구\"]\n",
    "df = pd.DataFrame(data, index=index, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['2010 - 2015 증가율'] = 1 - df['2010']/df['2015']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>지역</th>\n",
       "      <th>2015</th>\n",
       "      <th>2010</th>\n",
       "      <th>2005</th>\n",
       "      <th>2000</th>\n",
       "      <th>2010 - 2015 증가율</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>서울</th>\n",
       "      <td>수도권</td>\n",
       "      <td>9904312</td>\n",
       "      <td>9631482</td>\n",
       "      <td>9762546</td>\n",
       "      <td>9853972</td>\n",
       "      <td>0.0275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>부산</th>\n",
       "      <td>경상권</td>\n",
       "      <td>3448737</td>\n",
       "      <td>3393191</td>\n",
       "      <td>3512547</td>\n",
       "      <td>3655437</td>\n",
       "      <td>0.0161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>인천</th>\n",
       "      <td>수도권</td>\n",
       "      <td>2890451</td>\n",
       "      <td>2632035</td>\n",
       "      <td>2517680</td>\n",
       "      <td>2466338</td>\n",
       "      <td>0.0894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>대구</th>\n",
       "      <td>경상권</td>\n",
       "      <td>2466052</td>\n",
       "      <td>2431774</td>\n",
       "      <td>2456016</td>\n",
       "      <td>2473990</td>\n",
       "      <td>0.0139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     지역     2015     2010     2005     2000  2010 - 2015 증가율\n",
       "서울  수도권  9904312  9631482  9762546  9853972           0.0275\n",
       "부산  경상권  3448737  3393191  3512547  3655437           0.0161\n",
       "인천  수도권  2890451  2632035  2517680  2466338           0.0894\n",
       "대구  경상권  2466052  2431774  2456016  2473990           0.0139"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = sns.load_dataset('titanic')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      577\n",
       "female    314\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1)\n",
    "\n",
    "#성별\n",
    "titanic.sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Third     491\n",
       "First     216\n",
       "Second    184\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 선실별\n",
    "titanic['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     549\n",
       "yes    342\n",
       "Name: alive, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사망/생존\n",
    "titanic.alive.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2)\n",
    "\n",
    "bins = [1, 15, 25, 35, 60, 99]\n",
    "labels = [\"미성년자\", \"청년\", \"중년\", \"장년\", \"노년\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['gen'] = pd.cut(titanic.age, bins, labels=labels)\n",
    "# titanic.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "청년      0.3114\n",
       "중년      0.2800\n",
       "장년      0.2786\n",
       "미성년자    0.0986\n",
       "노년      0.0314\n",
       "Name: gen, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate = titanic.gen.value_counts()/sum(titanic.gen.value_counts())\n",
    "rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
       "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
       "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
       "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
       "4       24.59  3.61  Female     No  Sun  Dinner     4"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips = sns.load_dataset(\"tips\")\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "      <th>tip_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size  tip_pct\n",
       "0       16.99  1.01  Female     No  Sun  Dinner     2     0.06\n",
       "1       10.34  1.66    Male     No  Sun  Dinner     3     0.16\n",
       "2       21.01  3.50    Male     No  Sun  Dinner     3     0.17\n",
       "3       23.68  3.31    Male     No  Sun  Dinner     2     0.14\n",
       "4       24.59  3.61  Female     No  Sun  Dinner     4     0.15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1)\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "\n",
    "tips['tip_pct'] = tips['tip'] / tips['total_bill']\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tip_pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Thur</th>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fri</th>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sat</th>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sun</th>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tip_pct\n",
       "day          \n",
       "Thur     0.16\n",
       "Fri      0.17\n",
       "Sat      0.15\n",
       "Sun      0.17"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips.pivot_table('tip_pct', 'day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('test.db') # 파일 DB 접속\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1)\n",
    "cur.execute('CREATE TABLE IF NOT EXISTS Eagles (back_no INT NOT NULL,name TEXT,position TEXT,PRIMARY KEY(back_no));')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2)\n",
    "sql = \"insert into Eagles(back_no,name,position) values (?, ?, ?)\"\n",
    "cur.execute(sql, (1, '홍길동', '투수'))\n",
    "cur.execute(sql, (8, '정근우', '내야수'))\n",
    "cur.execute(sql, (4, '박진원', '볼보이'))\n",
    "cur.execute(sql, (11, '파이썬', '일루수'))\n",
    "cur.execute(sql, (17, '쥬피터', '삼루수'))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, '홍길동', '투수'),\n",
       " (8, '정근우', '내야수'),\n",
       " (4, '박진원', '볼보이'),\n",
       " (11, '파이썬', '일루수'),\n",
       " (17, '쥬피터', '삼루수')]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3)\n",
    "cur = conn.cursor()\n",
    "cur.execute('SELECT * FROM Eagles')\n",
    "rows = cur.fetchall()\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, '홍길동', '투수'),\n",
       " (8, '정근우', '외야수'),\n",
       " (4, '박진원', '볼보이'),\n",
       " (11, '파이썬', '일루수'),\n",
       " (17, '쥬피터', '삼루수')]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4)\n",
    "\n",
    "cur.execute(\"UPDATE Eagles SET position=? WHERE back_no=?;\",('외야수',8))\n",
    "\n",
    "cur.execute('SELECT * FROM Eagles')\n",
    "rows = cur.fetchall()\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5)\n",
    "\n",
    "cur.execute('SELECT MAX(back_no) FROM Eagles')\n",
    "del_no = cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"DELETE FROM Eagles WHERE back_no=17;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, '홍길동', '투수'), (8, '정근우', '외야수'), (4, '박진원', '볼보이'), (11, '파이썬', '일루수')]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('SELECT * FROM Eagles')\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = cur.fetchall()\n",
    "rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-3,4)\n",
    "y = sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Sigmoid x PLOT')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEVCAYAAAAb/KWvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8VOXZ//HPRdj3Pez7GkBFAkStigsWa6u12hbcN7BP6697qz611kfbp7V9qrWtXcDdWuniUlttFa1rNWwuLGEHgYCEhEAghJDt+v1xJjrEhAzJJGdm8n2/XvPKzJz7nLkOCd/cuec+95i7IyIiqaVV2AWIiEj8KdxFRFKQwl1EJAUp3EVEUpDCXUQkBSncRURSkMI9BZnZK2bmZnZb2LU0JzObETnvBs3vbez+IolE4Z6gLPB5M3vKzLaa2SEzKzazTWb2hpndZWYXmlnXsGuVpmVmt1X/0qlxKzWzXDN7xsy+YGZWy75XRbUf1sDXTzOzS83sL2a2xcwOmtkBM9toZo+a2QV17DejjrpjvTWoXgm0DrsA+Tgz6w48DZwe9XQFUAIMAUYApwDfAK4GHqpxiG3AOqCgqWtNMCUE553K8qLudwMGRm6fAa4yswvd/XC8XszMJgN/BMZFPV1M0DEcGbldZmZLgNnuviWqXVmNeqP1BNoA5UBhHW0qG1F6i6eee2J6hCDYK4GfA2OAdu7eC+gAHA/cCLxX287ufoW7j3P3XzdTvQnB3ZdEzntc/a2Tk7v3q74BnYCJwKLI5nOBH8brtczsNOB1gmDfC3wL6O/uXdy9EzAM+AHBL9VpQLaZffhv7+5vRtdbo/Y3I83qbOPu2+N1Li2Rwj3BmNlogl4YwC3u/m133+DuVQDuXuHuK9z9p+5+AvCn0IqVULl7lbuvBs4HNkaevt7MGv0XuZn1JfjZ6gTkAtPc/S533xX1+lvd/XaCjsg+oC/wVzNr39jXl8ZTuCeeE6Lu/62+xu5+qOZz9b2hamZtzOwbZvZuZPy0MLLPxfXtHzUeOsPMekXG/jdF3hPYama/NrM+Ue2HmtlvI2O1pWa2zcx+bmZdjnZeZjbZzB6JHLPUzPaa2Ztm9nUza1fHPvW+IWpm48zsMTPbFTnuZjP7lZmlH62eemo9xcwqIq/99TraDDKzPZE28xv6WrVx91LgL5GHXThyCKWhbgT6Re5f7u4b62ro7suAr0YeTgCujcPrS2O5u24JdAM+D3jkNrOBx3glsv9ttWzrBLwa9RoVBGOeVZHHP65n/+r9rgC2R+4XA4ejtuUA3YGpQH7kuSKC8dXqNm8AaXXU//WoepygV1gW9fg9guGBmvvNqG5Tx3FnAaVRxzkAHIrc30nw/kWd+9fzb/79yL6Hgck1trWK+jddA3Q8xmPfVl9dwJejzuvkqOevinp+WIyv1yby/XLg5Rj3MYK/HhzIOYaf0VfC+H/WEm7quSeepQQ/9AA/N7MxcT7+z4HTCMLzRqC7u/ck+JP6l8BNBGP69bmH4A3bLHfvDHQG5hCMv44H7iDoTa4AJrp7N4Je5f8jeC/hFIIwPYKZfRq4myAs/gaMcPfukeNfQRDIxxH8+Z8W60mb2SCCYYZ2kZqmu3sXgl9250ZquivW49XiRwSB1RZYaGadorbdQjB0cZjgTceSRrxOXYZF3a/rDcpYZQLVs7CeiGUHDxL76cjD8WbW72jtpRmE/dtFt4/fgPl81NuqAt4G7gWuIXgDzerZ/xVq6XkTzLSpjGy7pY59H4p67dtq2V69bRfQq5btt0e1WUXwRnDNNo9Etr9Yy7bVkW2vU0vPnuD9iOrjX1xj2wzq6OECv4lsKwD61rJ9IlF/HTTw+zYwcnwHHow8dwrBX0cOfLWBx73taHURBPGOSJs9QKuobVdx7D3366L2OeUY6rwsar+zYvwZfSVe/290O/Kmnnti+jJBz/cgQQ92cuS5+4GVwK7IWPexjhNfRDBEUELQO67NHTEea4G776nl+eej7t/ltU/Lq25zXPSTZnYckFFdh7t/bCqcu/8dWBJ5OCeWQiPzv78Yefg7d99dy3FXAX+N5Xh1cfcdBL+AIZiW+GWCaYRpwLPu/svGHL8mM+tuZmcB/wYGRJ6+xyNvvjdCr6j7tX2P6xI99bZXna2kWSjcE5AHM2JuJegJXg7cRzDOXBZp0pdgjvsqM5t2DIc+MfJ1mbsfrOO1NxGMpddnSR3PR89rXlpPmx41ns+MfK0geF+gLtVT/zKP0ibacIJ51RAEYV2Oti0m7v4MUD0F9V6Cv5Y+IOhBN1r0RT4E0xNfBKZENv+BYHgono7lat2PXUQl4VG4JzB3L3L3P7j7XA+mPXYDZgJ/jzTpDTxxDFPPqmex7Kyn3Y4YjnWgjucrjqFNzSl7fSNfC+ro8VfLrdG+PtHtjnZuuUfZdiy+XeN1rnH3eF1Qlhd120YwZHc/cKa7X17bXzsNEN1b730M+zW0xy9NQFeoJhEPpry9CLxoZg8BVwKDCGaBPH2UXatV96zq642F3QOLtbfYkDVgmmPdmPMI/uqqdjrwr3gc2IMLgJpaTtT9E4H/xLjf5Kj7q+NXjjSEeu7JK3qu9NgY96keax5w1Fb1b28q1fX1qWsue8SgyNf8Yzxu9L61GXiUbTExs8EEw2gQzMoB+K6ZndnYYzejpXz0V9dFsewQeV/js5GHazzqYicJh8I9eRVH3Y91LZG3I18za0zV+5CZjQAGN6awRlgW+dqaI9fVqensyNe6xvRr2sJH0wPPOEq7RgVwZGrmYwTvJeQAWcBTBP/PHjWzpHiT0d3L+egX1OlmNiOG3S4jWPMIgplJEjKFe4Ixs+Exzm2/Mur+23W2OtKTBFMrOwFfq6PN92I8Vty5+wo+GhK4pbZ57Gb2KWB65OHjMR7XgT9HHn7JzD42jmxmGcDFx1z0kW4BTiX4ZTvHg6uHryMYyx8APNjI4zenO/noL55HzWxkXQ3NbArBNRIQXKR1fxPXJjFQuCeeCcAaM3vWzK6IXvY0smzAZDN7EPhm5OklBFd71svdt/LRf7zbzezbZtY5cuxeZnYXwVS+ffE5lQa5MfL1VIILlYbDh+d+KR8F+pvE9j5DtR8TDDX0BhaZWWbkuGZm5wD/JJgi2iBmdgrBVaoA34n8osLdCwl6tVXAZ8zshoa+Rhz0MLPeR7lVzyjC3fMIpo+WEAxlLY0sWfHh9FszG2xm3wdeI7giuYDg2oOPLYkhIQh7or1uR96AT/LRhSDVt8MEsw+qajy/HBhQyzFeoe6LkDoTXCBU1/IDd/DR8gQ31bJ/9X4z6qh/WFSbYXW0mVHdpo7t36hxrns5cnmDFXWcd33HPY8jlx/YTxBejVp+gCDYtkb2/Ucdbaov7joETDrG49/WkLoi+15Vy89TXbd9teyfSbCMcnS7/QTDgtHPLQVGHkNd1T+jr4T9fy5Vb+q5Jxh3fx4YTTBs8heCP3MPEwRICbCBYIhhNjDV3eub1ljz+MXAWcB3CEKyjGB2zKvA59z9+5HXgpB68O5+N0Go/IFgzn1HglDMJviLZdqxnnfkuM8SzP5YSDDk0JZgSuGvCWZ6bGlgyQsI5rPvopYlFSL+h+CvjfYEyxN0aOBrNSsPFgWbQLD0w5MEv8SqZ9ltJrhI63ME35NNoRQptbLIb1ERACLDNHsIgu80d3895JJEpAHUc5eavkkQ7IXEPhtFRBKMwr2FMbMuZrbQzGZZ8HF+1c8PNbOfEYzvAvzCg4umRCQJaVimhYkE+t6op6ovVon+8IwnCJamjV5KQESSiMK9hbHgI9iuJ1ijZiLBejMdCKaxLSNYjvcJ1w+GSFJTuIuIpKB6x9zN7AEz221mq+rYbmb2SzPbaGYrzOzE2tqJiEjzieUN1YcIVh2sy7kE87JHA/OA3za+LBERaYx6w93dX+Pon8l4AfCIB7KB7mbWP14FiojIsYvHeu4DOfKTe3Ijz31Qs6GZzSPo3dOpU6cp48aNi8PLi4i0HMuXLy9w9z71tYtHuNf2wQ61vkvr7vOJrEOemZnpy5Ytq62ZiIjUwcy2xtIuHhcx5XLk+t+DqP9j3EREpAnFI9yfAa6IzJrJAorc/WNDMiIi0nzqHZYxs8cJllLtbWa5wA+ANgDu/jvgOeBTwEaCVQvrWhVPRESaSb3h7u5z6tnuwFfiVpGIiDSaFg4TEUlBCncRkRSkcBcRSUEKdxGRZuDurN5ZxC9eXM/aXfub/PXicRGTiIjUoryyiiVbClmUk8einDx27DuEGfTq3I5x/bo26Wsr3EVE4uhAaTmvrs9nUU4eL6/dzf7SCtq1bsWpo3vztbNGc+b4vvTu3K7J61C4i4g0Ut7+0g97529t2kNZZRU9O7XlnAn9mJmRzqmje9OxbfPGrcJdROQYuTvr84pZlLOLRTl5vJdbBMDQXh258uShzMzox5ShPUhrVdvSW81D4S4iEoOKyiqWb93LC5Ee+rbCEgCOH9yd73xyLDMz0hndtzNm4QV6NIW7iEgdSsoqeG19AYty8vj32jz2lpTTNq0VJ4/qxfWnj+Ds8emkd20fdpm1UriLiETJP3CYl9YEvfM3NhZwuKKKbh3acOa4vszMSOe0MX3o3C7xozPxKxQRaWIbdxdH3hDdxTvb9+EOA7t3YM60IZwzIZ2pw3rSJi25LgtSuItIi1NZ5by7/aPx8835BwGYOLArXz9rDDMz0hnfv0vCjJ83hMJdRFqE0vJK3tgQjJ+/tDaPguIyWrcyThrZi6tOHsbZ49MZ0L1D2GXGjcJdRFJW4cEy/r12Ny+s3sXrGwo4VF5Jl3atOX1sH2ZmpDNjbF+6dWgTdplNQuEuIill656DLMrJ44WcPJa9X0iVQ7+u7bl4yiBmZqSTNaIXbVsn1/h5QyjcRSSpVVU5K3cU8ULkgqL1ecUAjOvXha+cMYqZGelMGtgtqcfPG0LhLiJJ53BFJW9t2sOinDxeXJNH3v7DpLUypg7rwfc/ncE5GekM7tkx7DJDpXAXkaRQVFLOy+t2sygnj1fX51N8uIKObdM4fUwwfn7G2L706NQ27DIThsJdRBLaB0WHuP3vOSzKyaOiyunduR2fOb4/52T046SRvWjfJi3sEhOSwl1EElJVlfPYkm3c+c+1VFRVce0nhvPJif04YVB3WoW4IFeyULiLSMLZlF/MzU+sZMn7hXxiVG/+98JJDOnVssfQj5XCXUQSRnllFfNf28w9L22gfetW/PTi4/j8lEEtbqZLPCjcRSQhrMjdx41PrGTNB/s5b1J/fnB+Bn27JOaKi8lA4S4ioTpUVsndL67nvtc306dLO+ZfPoVzJvQLu6ykp3AXkdC8ubGAm55cybbCEuZMG8JN545L2eUAmpvCXUSaXVFJOf/73Br+tGw7w3p15PG5WZw0slfYZaUUhbuINKt/rfqA7/9tNYUHy7j+9BF84+wxmqveBBTuItIsdu8v5da/reZfq3eR0b8rD141lYkDu4VdVspSuItIk3J3/rxsOz96dg2lFVV8d9ZY5p46Iuk+2SjZKNxFpMls3XOQm59cyZub9jBteE9+8rlJjOjTOeyyWgSFu4jEXUVlFQ/8Zwt3LVpPm1at+NGFE5kzdYiWDWhGCncRiaucnfu56ckVrMgt4uzx6fzwsxPp100XIzU3hbuIxEVpeSW/+vcGfv/qZrp3bMOvL5nMeZP6a+mAkMQU7mY2C7gHSAPuc/ef1Ng+BHgY6B5pc5O7PxfnWkUkQS3ZUshNT65gc/5BLjpxELecN15rq4es3nA3szTgXmAmkAssNbNn3D0nqtktwJ/d/bdmlgE8BwxrgnpFJIEcKC3nzn+t5Q/Z2xjUowOPXDON08b0CbssIbae+zRgo7tvBjCzhcAFQHS4O9A1cr8bsDOeRYpI4nlpTR63PL2KXftLueaU4XzrnDF0aqeR3kQRy3diILA96nEuML1Gm9uAF8zs/wGdgLPjUp2IJJyC4sP8z99z+Pt7OxmT3pnfXHoyk4f0CLssqSGWcK/t3RCv8XgO8JC7/9zMTgIeNbOJ7l51xIHM5gHzAIYMGdKQekUkJO7OU+/s4I5/5FB8uIJvnD2G/5oxkratdTFSIool3HOBwVGPB/HxYZdrgVkA7v6WmbUHegO7oxu5+3xgPkBmZmbNXxAikqBy95bwvadW8er6fE4c0p07LzqO0eldwi5LjiKWcF8KjDaz4cAOYDZwSY0224CzgIfMbDzQHsiPZ6Ei0vwqq5xH3nqfnz2/DoDbPpPB5ScNI00XIyW8esPd3SvM7AbgeYJpjg+4+2ozux1Y5u7PAN8CFpjZNwiGbK5yd/XMRZLYhrwDfPeJFbyzbR+nj+nDjy6cyKAe+hzTZBHTW9uROevP1Xju1qj7OcAp8S1NRMJQVlHFb17ZyL0vb6Rzu9bc/cXj+ewJA3UxUpLRvCUR+dA72/Zy4xMrWJ9XzPnHD+DWz2TQu3O7sMuSBlC4iwglZRX83/PrefDNLfTr2p77r8zkrPHpYZcljaBwF2nhXlufz38/tZLcvYe4LGsIN84aR5f2+hzTZKdwF2mh9pWUccc/1vDE27mM6NOJv3zpJKYO6xl2WRInCneRFsbdeXblB9z2zGr2lZRzwxmjuOHMUfoc0xSjcBdpQT4oOsT3n17Fi2t2c9ygbjxyzXQyBnStf0dJOgp3kRagqsp5fOk2fvLcWsqrqvjep8Zz9SnDaK3PMU1ZCneRFLc5v5ibnlzJki2FnDyyFz/+3CSG9uoUdlnSxBTuIimqvLKKBa9v5hcvbqBd61bcedEkvpA5WBcjtRAKd5EUVFpeyfWPLufV9fnMmtCP2y+YQN+u+hzTlkThLpJiSssrmffocl7fkM+PLpzIpdOHhl2ShEDhLpJCSssrmfvIMt7YWMCdnzuOL0wdXP9OkpIU7iIp4ohgv+g4vpCpYG/JFO4iKeBQWRDs/9lUwE8vOo7PK9hbPIW7SJI7VFbJdY8s5c1Ne/jZxcdz8ZRBYZckCUDhLpLEDpVVcu3DS3lr8x7+7+LjuUjBLhEKd5EkVVJWwbUPLWPxlj3c9YXjuXCygl0+onAXSUIlZRVc89BSlmwp5K4vnMBnJw8MuyRJMAp3kSRTUlbB1Q8uZen7hdz9xRO44AQFu3ycwl0kiRw8XMHVDy1lmYJd6qFwF0kSBw8HPfZlWwv5xezJnH/8gLBLkgSmcBdJAsWHK7j6wSW8vW0f98yezGcU7FIPhbtIgis+XMFVDyzhne37uGf2CXz6OAW71E/hLpLADpSWc9WDS3l3+z5+OXsy5x3XP+ySJEko3EUS1IHScq58YAnv5RbxqzmT+dQkBbvETuEukoD2R4J9ZW4Rv54zmXMV7HKMFO4iCWZ/aTlX3L+EVTuK+PUlJzJrYr+wS5IkpHAXSSDRwX7vpSfyyQkKdmkYhbtIgig6VM4VDywhZ2cRv7n0RM5RsEsjKNxFEkDRoXKuuH8xOR/s5zeXTmFmRnrYJUmSU7iLhKyopJzLH1jMmg/289tLp3C2gl3iQOEuEqKiknIuu38x63Yd4HeXTeGs8Qp2iQ+Fu0hI9pWUcdn9i1m/q5jfXX4iZ45TsEv8KNxFQrCvpIxL71vMhrxifn/5FM4Y1zfskiTFKNxFmtneg0Gwb8wv5vdXTOGMsQp2ib9WsTQys1lmts7MNprZTXW0+YKZ5ZjZajP7Y3zLFEkN0cE+/3IFuzSdenvuZpYG3AvMBHKBpWb2jLvnRLUZDdwMnOLue81MP7EiNRRGgn1TfjELrsjk9DF9wi5JUlgsPfdpwEZ33+zuZcBC4IIabeYC97r7XgB33x3fMkWSW+HBMi5ZkM3m/GLuU7BLM4gl3AcC26Me50aeizYGGGNm/zGzbDObVduBzGyemS0zs2X5+fkNq1gkyewpPswlC7LZUnCQ+67M5DQFuzSDWMLdannOazxuDYwGZgBzgPvMrPvHdnKf7+6Z7p7Zp49+wCX1FRQf5pIFi9lScJD7r5zKqaP1cy/NI5ZwzwUGRz0eBOyspc3f3L3c3bcA6wjCXqTFKoj02LcWHuSBq6byidG9wy5JWpBYwn0pMNrMhptZW2A28EyNNk8DZwCYWW+CYZrN8SxUJJnkHzjMnPnZbCss4YErp3LKKAW7NK96w93dK4AbgOeBNcCf3X21md1uZudHmj0P7DGzHOBl4DvuvqepihZJZPkHgh779r0lPHDVVE5WsEsIzL3m8HnzyMzM9GXLloXy2iJNZfeBUi5ZsJgdew/xwFVTOWlkr7BLkhRjZsvdPbO+drpCVSROdu8vZc6CbHbuK+XBq6eSNULBLuFRuIvEwe79pcxekM2uolIeunoq0xXsEjKFu0gjHRns05g2vGfYJYnEtraMiNQub38ps+cr2CXxqOcu0kC7ioIx9t37S3n4mmlMHaZgl8ShcBdpgJrBnqlglwSjcBc5Rh8UHWLO/GwKist45NppTBmqYJfEo3AXOQY79x1izoJs9hSX8fA105gytEfYJYnUSuEuEqMd+4Ie+96DQY/9xCEKdklcCneRGOzYd4jZ899i38FyHrl2GpMV7JLgFO4i9cjdW8KcBdnsKynn0eumc8Lgj61mLZJwFO4iR7G9MAj2okPl/OHa6RyvYJckoXAXqcP2whJmz8/mQGk5j103neMGKdgleSjcRWpxZLBnMWlQt7BLEjkmWn5ApIbqYC8+XKFgl6SlnrtIlG17gjH2INinM3Gggl2Sk8JdJGLrnoPMmZ9NSXmlgl2SnsJdhCDYZ8/P5lAk2CcMULBLclO4S4v3fkEQ7IcrKvnjdVlkDOgadkkijaY3VKVF2xIV7I8p2CWFqOcuLdbm/GLmLMimvNL549wsxvdXsEvqULhLi7Q5v5jZ87OpqHL+OHc64/op2CW1KNylxdmUX8yc+dlUVjmPz81ibL8uYZckEncKd2lRNu4OhmLcncfnZTEmXcEuqUnhLi3GEcE+N4vRCnZJYQp3aRE27j7A7PmLARTs0iIo3CXlbcg7wJwF2YCxcN50RvVVsEvq0zx3SWnrI8FuZiycl6VglxZD4S4pa92uA8yZHwT743OzGNW3c9gliTQbDctISlq36wCXLMgmrZXx+LwsRvZRsEvLop67pJy1u/YzZ0E2rdOCoRgFu7RE6rlLSlnzwX4uvW8xbdNa8fi8LIb37hR2SSKhUM9dUkbOzv1csiCbtmmtWKhglxZO4S4pIWfnfi69L5v2bdJYOC+LYQp2aeEU7pL0Vu8s4pL7sumgYBf5UEzhbmazzGydmW00s5uO0u5iM3Mzy4xfiSJ1W7WjiEsWLKZjmzQWzjuJob0U7CIQQ7ibWRpwL3AukAHMMbOMWtp1Ab4KLI53kSK1WbWjiEvvW0zndq1ZOO8khvTqGHZJIgkjlp77NGCju2929zJgIXBBLe3uAH4KlMaxPpFarcyNDvYsBbtIDbGE+0Bge9Tj3MhzHzKzycBgd//H0Q5kZvPMbJmZLcvPzz/mYkUAVuTu49L7sj8M9sE9FewiNcUS7lbLc/7hRrNWwN3At+o7kLvPd/dMd8/s06dP7FWKRKzI3cdl9y2ma4c2CnaRo4gl3HOBwVGPBwE7ox53ASYCr5jZ+0AW8IzeVJV4e2/7Pi5VsIvEJJZwXwqMNrPhZtYWmA08U73R3Yvcvbe7D3P3YUA2cL67L2uSiqVFend70GPv3rENf7r+JAb1ULCLHE294e7uFcANwPPAGuDP7r7azG43s/ObukCRd7bt5fL7FtOjU1sWzjuJgd07hF2SSMKLaW0Zd38OeK7Gc7fW0XZG48sSCby9bS9X3L+EXp3b8vjcLAYo2EViooXDJGEt37qXKx8Ign3hvCz6d1Owi8RKyw9IQlq+tZArH1hCbwW7SIMo3CXhLHu/kCvuX0KfLu1YOO8kBbtIAyjcJaEsfT/osfft2p7H52bRr1v7sEsSSUoKd0kYS7YEwZ7etT0L5ynYRRpDb6hKQli8eQ9XP7SUft3as3BuFn27KthFGkM9dwlddbD3V7CLxI3CXUKVvXkPVz24lAHdO/D4PAW7SLxoWEZC89amPVzz0FIG9ujA43Oz6NOlXdgliaQM9dwlFG9uKuDqh5YwSMEu0iTUc5dm9+bGAq55eClDenbkj3Oz6N1ZwS4Sb+q5S7P6z8YCrn5oKUN7dlKwizQh9dyl2byxoYBrH17K8N6deOy66fRSsIs0GfXcpVm8viFfwS7SjNRzlyb32vp8rntkGSN6B0MxPTu1DbskkZSnnrs0qVcjwT6yT2cFu0gzUs9dmswr63Yz79HljOrTmceum04PBbtIs1HPXZrEy+t2M++R5Yzuq2AXCYN67hJ3L6/dzfWPLmdMv8784drpdO+oYBdpbuq5S1y9tCZPwS6SABTuEjcvrcnjS39Yzth+XXjs2iwFu0iINCwjcfFiTh7/9dhyxvfvyqPXTqdbhzZhlyTSoincpVFKyir4+QvrefA/W5g0sBuPKNhFEoLCXRrsjQ0F3PzUCrYXHuKS6UO4+dxxdGmvYBdJBAp3OWZFJeX88Nkc/rI8lxG9O/GneVlMH9Er7LJEJIrCXWLm7vxz1S5u/dtq9paU8eUZI/nqWaNp3yYt7NJEpAaFu8Qkb38ptzy9ikU5eUwc2JWHr5nKhAHdwi5LROqgcJejqqpyFi7dzo+fW0NZZRU3nzuOaz8xnNZpmkUrksgU7lKn9wsOctOTK8jeXEjWiJ785HPHMax3p7DLEpEYKNzlYyoqq7jvjS3cvWg9bVu34sefm8TsqYMxs7BLE5EYKdzlCKt3FnHjEytYtWM/52Skc8dnJ5LetX3YZYnIMVK4CwCl5ZXc89IG5r+2mR4d2/KbS0/k3In91FsXSVIKdyF78x5ufnIlWwoO8oXMQfz3p8ZrXRiRJKdwb8H2l5bzk3+u5Y+LtzGkZ0ceu246p4zqHXZZIhIHMYW7mc0C7gHSgPvc/Sc1tn8TuA6oAPKBa9x9a5xrlThalJPHLU+vJP/AYa77xHC+ec4YOrbV73qRVFHv/2YzSwPuBWYCucBSM3vG3XOimr0DZLp7iZn9F/BT4ItNUbA0Tv6Bw9z299U8u+IDxvXrwvzLMzl+cPewyxKROIulqzYN2OjumwEVuaqTAAAJ5ElEQVTMbCFwAfBhuLv7y1Hts4HL4lmkNJ6788TbO7jjHzkcKqvkWzPHcP3pI2nbWhcjiaSiWMJ9ILA96nEuMP0o7a8F/tmYoiS+theW8N9PreT1DQVkDu3BTy6axKi+XcIuS0SaUCzhXttcOK+1odllQCZweh3b5wHzAIYMGRJjidJQlVXOQ2++z/89v45WBrdfMIHLpg+lVStNbxRJdbGEey4wOOrxIGBnzUZmdjbwPeB0dz9c24HcfT4wHyAzM7PWXxASH+t2HeDGJ1bw7vZ9nDG2Dz+8cBIDu3cIuywRaSaxhPtSYLSZDQd2ALOBS6IbmNlk4PfALHffHfcqJWaHKyq59+VN/PaVjXRp34Z7Zp/A+ccP0MVIIi1MveHu7hVmdgPwPMFUyAfcfbWZ3Q4sc/dngJ8BnYG/REJkm7uf34R1Sy2Wb93LjU+sYOPuYj57wgBu/cwEenbSxUgiLVFME5vd/TnguRrP3Rp1/+w41yXH4ODhCn72/Doefut9+ndtz4NXT+WMsX3DLktEQqSrVpLcK+t2872nVrGz6BBXZA3lO7PG0bmdvq0iLZ1SIEkVHizjjn/k8NQ7OxjZpxN//dJJTBnaM+yyRCRBKNyTjLvzzHs7uf3vORQdKuerZ47iK2eOol1rfY6piHxE4Z5Edu47xPefXsVLa3dz/KBuPDZ3OuP6dQ27LBFJQAr3JFBV5Ty2ZBt3/nMtlVXOLeeN5+pThpOmi5FEpA4K9wS3cXcxNz+5gqXv7+UTo3rz489NYnDPjmGXJSIJTuGeoMorq/j9q5v45Usb6dA2jZ9dfBwXTxmki5FEJCYK9wS0Incf3/3rCtbuOsB5k/rzg/Mz6NtFn2MqIrFTuCeQQ2WV3LVoHfe/sYU+Xdox//IpnDOhX9hliUgSUrgniDc3FnDTkyvZVljCnGlDuOnccXTr0CbsskQkSSncQ1ZUUs7/PreGPy3bzrBeHXl8bhYnjewVdlkikuQU7iEpKD7M86t38YsXN1B4sIwvnT6Sr589mvZtdDGSiDSewr0ZbcovZlFOHoty8nh7217cYeLArjx41VQmDuwWdnkikkIU7k2oqsp5Z/teXogE+ub8gwBMGNCVr501mpkZ6WT076rpjSISdwr3OCstr+Q/GwtYlJPHi2t2U1B8mNatjKwRvbjypGGcnZGuT0QSkSancI+DvQfLeGntbhbl7OK19QUcKq+kc7vWzBjbh5kZ6cwY21czX0SkWSncG2jbnhJeyNnFCzl5LHu/kCqHfl3bc9GUgczM6EfWiJ5aqVFEQqNwj1FVlbNyR9GHb4iuyzsAwLh+XfjKGaOYmZHOpIHdNH4uIglB4X4UhysqeWvTnsj4eR55+w/TymDqsJ58/9MZzByfzpBeWsRLRBKPwr2GokPlvLJuNy/k5PHqunyKD1fQsW0ap40Oxs/PHNeXHvrQaRFJcAp3YMe+QyxavYtFa/JYvLmQiiqnd+d2fOb4/szMSOfkkb11cZGIJJUWGe7uzuqd+z8cP8/5YD8AI/t04rpTR3DOhHROGNSdVvowDBFJUi0m3Msrq1iypfDDQN+x7xBmMGVID24+dxwzM9IZ0adz2GWKiMRFSof7gdJyXl2fz6KcPF5eu5v9pRW0a92KU0f34WtnjebM8X3p3bld2GWKiMRdyoV73v5SFuXk8UJOHtmb9lBWWUXPTm05Z0I/Zmakc+ro3nRsm3KnLSJyhKRPOXdnfV4xi3J2sSgnj/dyiwAY1qsjV548lJkZ/ZgytIc+TFpEWpSkDPeKyiqWbd374fj5tsISAI4f3J3vfHIs52SkM6pvZ11QJCItVtKF+8Il27jzX2vZW1JO27RWnDyqF9efPoKzx6eT3lWfMyoiAkkY7v26tWfG2L7MzEjntDF96Nwu6U5BRKTJJV0yzhjblxlj+4ZdhohIQmsVdgEiIhJ/CncRkRSkcBcRSUEKdxGRFKRwFxFJQTGFu5nNMrN1ZrbRzG6qZXs7M/tTZPtiMxsW70JFRCR29Ya7maUB9wLnAhnAHDPLqNHsWmCvu48C7gbujHehIiISu1h67tOAje6+2d3LgIXABTXaXAA8HLn/V+As07X/IiKhieUipoHA9qjHucD0utq4e4WZFQG9gILoRmY2D5gXeVhsZusaUjTQu+axk5jOJfGkynmAziVRNeZchsbSKJZwr60H7g1og7vPB+bH8JpHL8hsmbtnNvY4iUDnknhS5TxA55KomuNcYhmWyQUGRz0eBOysq42ZtQa6AYXxKFBERI5dLOG+FBhtZsPNrC0wG3imRptngCsj9y8G/u3uH+u5i4hI86h3WCYyhn4D8DyQBjzg7qvN7HZgmbs/A9wPPGpmGwl67LObsmjiMLSTQHQuiSdVzgN0Lomqyc/F1MEWEUk9ukJVRCQFKdxFRFJQ0oa7md1hZivM7F0ze8HMBoRdU0OZ2c/MbG3kfJ4ys+5h19QQZvZ5M1ttZlVmlpRT1upbaiNZmNkDZrbbzFaFXUtjmNlgM3vZzNZEfra+FnZNDWVm7c1siZm9FzmX/2nS10vWMXcz6+ru+yP3vwpkuPuXQi6rQczsHIIZRhVmdieAu98YclnHzMzGA1XA74Fvu/uykEs6JpGlNtYDMwmm9y4F5rh7TqiFNYCZnQYUA4+4+8Sw62koM+sP9Hf3t82sC7Ac+GySfk8M6OTuxWbWBngD+Jq7ZzfF6yVtz7062CM6UctFU8nC3V9w94rIw2yCawmSjruvcfeGXnWcCGJZaiMpuPtrpMC1Ju7+gbu/Hbl/AFhDcEV80vFAceRhm8ityXIracMdwMx+ZGbbgUuBW8OuJ06uAf4ZdhEtVG1LbSRlkKSiyGqzk4HF4VbScGaWZmbvAruBRe7eZOeS0OFuZi+a2apabhcAuPv33H0w8BhwQ7jVHl195xJp8z2gguB8ElIs55HEYlpGQ5qfmXUGngC+XuOv9qTi7pXufgLBX+fTzKzJhsxiWVsmNO5+doxN/wg8C/ygCctplPrOxcyuBD4NnJXIV/cew/ckGcWy1IY0s8j49BPAY+7+ZNj1xIO77zOzV4BZQJO86Z3QPfejMbPRUQ/PB9aGVUtjmdks4EbgfHcvCbueFiyWpTakGUXehLwfWOPud4VdT2OYWZ/qmXBm1gE4mybMrWSeLfMEMJZgdsZW4EvuviPcqhomsmxDO2BP5KnsZJz5Y2YXAr8C+gD7gHfd/ZPhVnVszOxTwC/4aKmNH4VcUoOY2ePADIKlZfOAH7j7/aEW1QBm9gngdWAlwf91gP929+fCq6phzOw4gs+9SCPoWP/Z3W9vstdL1nAXEZG6Je2wjIiI1E3hLiKSghTuIiIpSOEuIpKCFO4iIilI4S4ikoIU7iIiKej/A/+PN7uBG6hXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,y)\n",
    "plt.title(\"Sigmoid x PLOT\",{'fontsize':25}, pad=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.\n",
    "\n",
    "\n",
    "1) ```gradient descent```\n",
    "  \n",
    "2) ```learning rate```\n",
    "  \n",
    "3) ```노드```  \n",
    "  \n",
    "4) ```relu```  \n",
    "  \n",
    "5) ```layer```  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset(\"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = iris.sample(frac=1)\n",
    "dataset = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,:4]\n",
    "Y = dataset[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_encoded = label_encoder.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# versicolor = 1, virginica = 2, setosa = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_Y = to_categorical(integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, encoded_Y, test_size=0.33, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=8, activation='relu', input_dim=4))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=8, activation='relu'))\n",
    "model.add(Dense(units=3, activation='softmax'))\n",
    "model.compile(optimizer=Adam(learning_rate=0.002),loss='categorical_crossentropy',  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples, validate on 50 samples\n",
      "Epoch 1/200\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 0.9275 - acc: 0.3300 - val_loss: 1.1722 - val_acc: 0.3400\n",
      "Epoch 2/200\n",
      "100/100 [==============================] - 0s 156us/sample - loss: 0.8524 - acc: 0.3400 - val_loss: 1.1620 - val_acc: 0.3400\n",
      "Epoch 3/200\n",
      "100/100 [==============================] - 0s 0s/sample - loss: 0.7758 - acc: 0.4700 - val_loss: 1.1539 - val_acc: 0.0800\n",
      "Epoch 4/200\n",
      "100/100 [==============================] - 0s 216us/sample - loss: 0.7550 - acc: 0.6500 - val_loss: 1.1462 - val_acc: 0.0000e+00\n",
      "Epoch 5/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.7270 - acc: 0.7500 - val_loss: 1.1386 - val_acc: 0.0000e+00\n",
      "Epoch 6/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.7057 - acc: 0.7800 - val_loss: 1.1317 - val_acc: 0.0400\n",
      "Epoch 7/200\n",
      "100/100 [==============================] - 0s 110us/sample - loss: 0.7051 - acc: 0.8000 - val_loss: 1.1263 - val_acc: 0.2400\n",
      "Epoch 8/200\n",
      "100/100 [==============================] - 0s 70us/sample - loss: 0.6617 - acc: 0.8200 - val_loss: 1.1220 - val_acc: 0.3800\n",
      "Epoch 9/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.6385 - acc: 0.8900 - val_loss: 1.1197 - val_acc: 0.4000\n",
      "Epoch 10/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.6138 - acc: 0.9100 - val_loss: 1.1161 - val_acc: 0.2800\n",
      "Epoch 11/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.5903 - acc: 0.9000 - val_loss: 1.1106 - val_acc: 0.2000\n",
      "Epoch 12/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.5727 - acc: 0.8900 - val_loss: 1.1038 - val_acc: 0.2200\n",
      "Epoch 13/200\n",
      "100/100 [==============================] - 0s 110us/sample - loss: 0.5499 - acc: 0.9000 - val_loss: 1.0931 - val_acc: 0.2600\n",
      "Epoch 14/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.5241 - acc: 0.9000 - val_loss: 1.0784 - val_acc: 0.3000\n",
      "Epoch 15/200\n",
      "100/100 [==============================] - 0s 70us/sample - loss: 0.4919 - acc: 0.9200 - val_loss: 1.0591 - val_acc: 0.3200\n",
      "Epoch 16/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.4981 - acc: 0.9300 - val_loss: 1.0354 - val_acc: 0.4800\n",
      "Epoch 17/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.4942 - acc: 0.8900 - val_loss: 1.0098 - val_acc: 0.5400\n",
      "Epoch 18/200\n",
      "100/100 [==============================] - 0s 70us/sample - loss: 0.4827 - acc: 0.9100 - val_loss: 0.9846 - val_acc: 0.5400\n",
      "Epoch 19/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.4031 - acc: 0.9400 - val_loss: 0.9728 - val_acc: 0.5400\n",
      "Epoch 20/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.4211 - acc: 0.9600 - val_loss: 0.9525 - val_acc: 0.5600\n",
      "Epoch 21/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.3984 - acc: 0.9000 - val_loss: 0.9315 - val_acc: 0.5800\n",
      "Epoch 22/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.3859 - acc: 0.9100 - val_loss: 0.9132 - val_acc: 0.6000\n",
      "Epoch 23/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.3177 - acc: 0.9200 - val_loss: 0.8853 - val_acc: 0.6000\n",
      "Epoch 24/200\n",
      "100/100 [==============================] - 0s 110us/sample - loss: 0.2994 - acc: 0.9700 - val_loss: 0.8593 - val_acc: 0.6000\n",
      "Epoch 25/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.2864 - acc: 0.9600 - val_loss: 0.8315 - val_acc: 0.6000\n",
      "Epoch 26/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.3009 - acc: 0.9100 - val_loss: 0.8022 - val_acc: 0.6200\n",
      "Epoch 27/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.2614 - acc: 0.9600 - val_loss: 0.7689 - val_acc: 0.6400\n",
      "Epoch 28/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.3149 - acc: 0.9000 - val_loss: 0.7364 - val_acc: 0.6400\n",
      "Epoch 29/200\n",
      "100/100 [==============================] - 0s 70us/sample - loss: 0.2614 - acc: 0.9500 - val_loss: 0.7015 - val_acc: 0.6800\n",
      "Epoch 30/200\n",
      "100/100 [==============================] - 0s 110us/sample - loss: 0.2393 - acc: 0.9600 - val_loss: 0.6615 - val_acc: 0.7600\n",
      "Epoch 31/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.2163 - acc: 0.9600 - val_loss: 0.6350 - val_acc: 0.8000\n",
      "Epoch 32/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.2599 - acc: 0.9200 - val_loss: 0.6021 - val_acc: 0.8400\n",
      "Epoch 33/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.2140 - acc: 0.9300 - val_loss: 0.5710 - val_acc: 0.9200\n",
      "Epoch 34/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.1958 - acc: 0.9500 - val_loss: 0.5549 - val_acc: 0.9200\n",
      "Epoch 35/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.2391 - acc: 0.9400 - val_loss: 0.5440 - val_acc: 0.9000\n",
      "Epoch 36/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.1806 - acc: 0.9800 - val_loss: 0.5456 - val_acc: 0.8800\n",
      "Epoch 37/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.2804 - acc: 0.8900 - val_loss: 0.5284 - val_acc: 0.9000\n",
      "Epoch 38/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.1761 - acc: 0.9700 - val_loss: 0.5039 - val_acc: 0.9200\n",
      "Epoch 39/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.1788 - acc: 0.9600 - val_loss: 0.4834 - val_acc: 0.9400\n",
      "Epoch 40/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.1576 - acc: 0.9600 - val_loss: 0.4642 - val_acc: 0.9400\n",
      "Epoch 41/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.1561 - acc: 0.9700 - val_loss: 0.4459 - val_acc: 0.9600\n",
      "Epoch 42/200\n",
      "100/100 [==============================] - 0s 110us/sample - loss: 0.1989 - acc: 0.9600 - val_loss: 0.4330 - val_acc: 0.9600\n",
      "Epoch 43/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.1457 - acc: 0.9600 - val_loss: 0.4264 - val_acc: 0.9400\n",
      "Epoch 44/200\n",
      "100/100 [==============================] - 0s 110us/sample - loss: 0.1442 - acc: 0.9700 - val_loss: 0.4097 - val_acc: 0.9600\n",
      "Epoch 45/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.2031 - acc: 0.9500 - val_loss: 0.3861 - val_acc: 0.9600\n",
      "Epoch 46/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.1659 - acc: 0.9500 - val_loss: 0.3714 - val_acc: 0.9600\n",
      "Epoch 47/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.1229 - acc: 0.9800 - val_loss: 0.3583 - val_acc: 0.9600\n",
      "Epoch 48/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.1638 - acc: 0.9600 - val_loss: 0.3444 - val_acc: 0.9800\n",
      "Epoch 49/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.1602 - acc: 0.9500 - val_loss: 0.3320 - val_acc: 0.9800\n",
      "Epoch 50/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.1509 - acc: 0.9400 - val_loss: 0.3207 - val_acc: 0.9400\n",
      "Epoch 51/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.1612 - acc: 0.9500 - val_loss: 0.3101 - val_acc: 0.9400\n",
      "Epoch 52/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.1737 - acc: 0.9300 - val_loss: 0.2996 - val_acc: 0.9800\n",
      "Epoch 53/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.1514 - acc: 0.9500 - val_loss: 0.2889 - val_acc: 0.9800\n",
      "Epoch 54/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.1319 - acc: 0.9600 - val_loss: 0.2800 - val_acc: 0.9400\n",
      "Epoch 55/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.1352 - acc: 0.9700 - val_loss: 0.2716 - val_acc: 0.9400\n",
      "Epoch 56/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.1526 - acc: 0.9600 - val_loss: 0.2622 - val_acc: 0.9400\n",
      "Epoch 57/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.1399 - acc: 0.9600 - val_loss: 0.2534 - val_acc: 0.9400\n",
      "Epoch 58/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.1143 - acc: 0.9400 - val_loss: 0.2479 - val_acc: 0.9400\n",
      "Epoch 59/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.1164 - acc: 0.9700 - val_loss: 0.2457 - val_acc: 0.9400\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 80us/sample - loss: 0.1114 - acc: 0.9800 - val_loss: 0.2488 - val_acc: 0.9400\n",
      "Epoch 61/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.1260 - acc: 0.9400 - val_loss: 0.2562 - val_acc: 0.9000\n",
      "Epoch 62/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.1203 - acc: 0.9700 - val_loss: 0.2660 - val_acc: 0.9000\n",
      "Epoch 63/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.0986 - acc: 0.9700 - val_loss: 0.2688 - val_acc: 0.8800\n",
      "Epoch 64/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.1065 - acc: 0.9700 - val_loss: 0.2707 - val_acc: 0.8800\n",
      "Epoch 65/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.1961 - acc: 0.9300 - val_loss: 0.2713 - val_acc: 0.8800\n",
      "Epoch 66/200\n",
      "100/100 [==============================] - 0s 110us/sample - loss: 0.0955 - acc: 0.9700 - val_loss: 0.2768 - val_acc: 0.8800\n",
      "Epoch 67/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.1585 - acc: 0.9700 - val_loss: 0.2800 - val_acc: 0.8800\n",
      "Epoch 68/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.0927 - acc: 0.9700 - val_loss: 0.2862 - val_acc: 0.8800\n",
      "Epoch 69/200\n",
      "100/100 [==============================] - 0s 70us/sample - loss: 0.1044 - acc: 0.9700 - val_loss: 0.2942 - val_acc: 0.8800\n",
      "Epoch 70/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.1024 - acc: 0.9700 - val_loss: 0.3105 - val_acc: 0.8600\n",
      "Epoch 71/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.0887 - acc: 0.9900 - val_loss: 0.3292 - val_acc: 0.8400\n",
      "Epoch 72/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.1095 - acc: 0.9600 - val_loss: 0.3493 - val_acc: 0.8400\n",
      "Epoch 73/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.1030 - acc: 0.9700 - val_loss: 0.3625 - val_acc: 0.8400\n",
      "Epoch 74/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.0820 - acc: 0.9800 - val_loss: 0.3814 - val_acc: 0.8400\n",
      "Epoch 75/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.1080 - acc: 0.9700 - val_loss: 0.4159 - val_acc: 0.8400\n",
      "Epoch 76/200\n",
      "100/100 [==============================] - 0s 110us/sample - loss: 0.0692 - acc: 0.9900 - val_loss: 0.4424 - val_acc: 0.8400\n",
      "Epoch 77/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.0914 - acc: 0.9600 - val_loss: 0.4472 - val_acc: 0.8400\n",
      "Epoch 78/200\n",
      "100/100 [==============================] - 0s 70us/sample - loss: 0.0962 - acc: 0.9700 - val_loss: 0.4302 - val_acc: 0.8400\n",
      "Epoch 79/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.1095 - acc: 0.9600 - val_loss: 0.4258 - val_acc: 0.8400\n",
      "Epoch 80/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.1028 - acc: 0.9600 - val_loss: 0.4659 - val_acc: 0.8400\n",
      "Epoch 81/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.1299 - acc: 0.9500 - val_loss: 0.4402 - val_acc: 0.8400\n",
      "Epoch 82/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.0998 - acc: 0.9700 - val_loss: 0.4417 - val_acc: 0.8400\n",
      "Epoch 83/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.1055 - acc: 0.9400 - val_loss: 0.3973 - val_acc: 0.8400\n",
      "Epoch 84/200\n",
      "100/100 [==============================] - 0s 110us/sample - loss: 0.1318 - acc: 0.9400 - val_loss: 0.2769 - val_acc: 0.8800\n",
      "Epoch 85/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.0915 - acc: 0.9500 - val_loss: 0.2419 - val_acc: 0.8800\n",
      "Epoch 86/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.0691 - acc: 0.9800 - val_loss: 0.2202 - val_acc: 0.8800\n",
      "Epoch 87/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.1149 - acc: 0.9500 - val_loss: 0.2143 - val_acc: 0.8800\n",
      "Epoch 88/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.1629 - acc: 0.9500 - val_loss: 0.2052 - val_acc: 0.8800\n",
      "Epoch 89/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.1598 - acc: 0.9500 - val_loss: 0.2055 - val_acc: 0.8800\n",
      "Epoch 90/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.0866 - acc: 0.9700 - val_loss: 0.1963 - val_acc: 0.9000\n",
      "Epoch 91/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.1500 - acc: 0.9500 - val_loss: 0.1563 - val_acc: 0.9200\n",
      "Epoch 92/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.0848 - acc: 0.9900 - val_loss: 0.1136 - val_acc: 0.9600\n",
      "Epoch 93/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.1267 - acc: 0.9600 - val_loss: 0.0865 - val_acc: 1.0000\n",
      "Epoch 94/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.0858 - acc: 0.9800 - val_loss: 0.0842 - val_acc: 0.9800\n",
      "Epoch 95/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.0914 - acc: 0.9700 - val_loss: 0.0876 - val_acc: 0.9800\n",
      "Epoch 96/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.1045 - acc: 0.9600 - val_loss: 0.0862 - val_acc: 0.9800\n",
      "Epoch 97/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.1095 - acc: 0.9500 - val_loss: 0.0820 - val_acc: 0.9800\n",
      "Epoch 98/200\n",
      "100/100 [==============================] - 0s 70us/sample - loss: 0.0943 - acc: 0.9600 - val_loss: 0.0773 - val_acc: 0.9800\n",
      "Epoch 99/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.1486 - acc: 0.9400 - val_loss: 0.0745 - val_acc: 0.9800\n",
      "Epoch 100/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.0838 - acc: 0.9600 - val_loss: 0.0775 - val_acc: 1.0000\n",
      "Epoch 101/200\n",
      "100/100 [==============================] - 0s 70us/sample - loss: 0.1062 - acc: 0.9800 - val_loss: 0.0803 - val_acc: 0.9800\n",
      "Epoch 102/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.0916 - acc: 0.9600 - val_loss: 0.0795 - val_acc: 0.9800\n",
      "Epoch 103/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.0990 - acc: 0.9600 - val_loss: 0.0791 - val_acc: 0.9800\n",
      "Epoch 104/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.0855 - acc: 0.9700 - val_loss: 0.0743 - val_acc: 0.9800\n",
      "Epoch 105/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.0892 - acc: 0.9700 - val_loss: 0.0707 - val_acc: 1.0000\n",
      "Epoch 106/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.1962 - acc: 0.9200 - val_loss: 0.0708 - val_acc: 1.0000\n",
      "Epoch 107/200\n",
      "100/100 [==============================] - 0s 60us/sample - loss: 0.0928 - acc: 0.9700 - val_loss: 0.0708 - val_acc: 1.0000\n",
      "Epoch 108/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.0848 - acc: 0.9700 - val_loss: 0.0721 - val_acc: 0.9800\n",
      "Epoch 109/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.1746 - acc: 0.9300 - val_loss: 0.0756 - val_acc: 0.9800\n",
      "Epoch 110/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.1446 - acc: 0.9400 - val_loss: 0.0878 - val_acc: 0.9800\n",
      "Epoch 111/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.1130 - acc: 0.9800 - val_loss: 0.1105 - val_acc: 0.9400\n",
      "Epoch 112/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.1056 - acc: 0.9600 - val_loss: 0.1275 - val_acc: 0.9400\n",
      "Epoch 113/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.0955 - acc: 0.9600 - val_loss: 0.1408 - val_acc: 0.9200\n",
      "Epoch 114/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.0993 - acc: 0.9700 - val_loss: 0.1398 - val_acc: 0.9200\n",
      "Epoch 115/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.1248 - acc: 0.9500 - val_loss: 0.1458 - val_acc: 0.9200\n",
      "Epoch 116/200\n",
      "100/100 [==============================] - 0s 110us/sample - loss: 0.1025 - acc: 0.9700 - val_loss: 0.1574 - val_acc: 0.9200\n",
      "Epoch 117/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.1054 - acc: 0.9700 - val_loss: 0.1720 - val_acc: 0.9200\n",
      "Epoch 118/200\n",
      "100/100 [==============================] - 0s 110us/sample - loss: 0.0785 - acc: 0.9700 - val_loss: 0.1687 - val_acc: 0.9200\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 90us/sample - loss: 0.1042 - acc: 0.9500 - val_loss: 0.1678 - val_acc: 0.9200\n",
      "Epoch 120/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.0789 - acc: 0.9800 - val_loss: 0.1623 - val_acc: 0.9200\n",
      "Epoch 121/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.1055 - acc: 0.9500 - val_loss: 0.1547 - val_acc: 0.9200\n",
      "Epoch 122/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.0762 - acc: 0.9700 - val_loss: 0.1349 - val_acc: 0.9200\n",
      "Epoch 123/200\n",
      "100/100 [==============================] - 0s 120us/sample - loss: 0.0557 - acc: 1.0000 - val_loss: 0.1323 - val_acc: 0.9200\n",
      "Epoch 124/200\n",
      "100/100 [==============================] - 0s 70us/sample - loss: 0.0950 - acc: 0.9700 - val_loss: 0.1351 - val_acc: 0.9200\n",
      "Epoch 125/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.1080 - acc: 0.9600 - val_loss: 0.1407 - val_acc: 0.9200\n",
      "Epoch 126/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.0896 - acc: 0.9700 - val_loss: 0.1124 - val_acc: 0.9400\n",
      "Epoch 127/200\n",
      "100/100 [==============================] - 0s 70us/sample - loss: 0.0845 - acc: 0.9700 - val_loss: 0.1103 - val_acc: 0.9400\n",
      "Epoch 128/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.1148 - acc: 0.9600 - val_loss: 0.1538 - val_acc: 0.9200\n",
      "Epoch 129/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.1221 - acc: 0.9600 - val_loss: 0.1756 - val_acc: 0.9200\n",
      "Epoch 130/200\n",
      "100/100 [==============================] - 0s 70us/sample - loss: 0.1056 - acc: 0.9600 - val_loss: 0.1946 - val_acc: 0.9000\n",
      "Epoch 131/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.1310 - acc: 0.9500 - val_loss: 0.2043 - val_acc: 0.9000\n",
      "Epoch 132/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.1300 - acc: 0.9500 - val_loss: 0.1906 - val_acc: 0.9000\n",
      "Epoch 133/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.1004 - acc: 0.9500 - val_loss: 0.1673 - val_acc: 0.9200\n",
      "Epoch 134/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.0863 - acc: 0.9600 - val_loss: 0.1542 - val_acc: 0.9200\n",
      "Epoch 135/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.1470 - acc: 0.9300 - val_loss: 0.1606 - val_acc: 0.9200\n",
      "Epoch 136/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.1081 - acc: 0.9600 - val_loss: 0.1571 - val_acc: 0.9200\n",
      "Epoch 137/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.0897 - acc: 0.9700 - val_loss: 0.1450 - val_acc: 0.9200\n",
      "Epoch 138/200\n",
      "100/100 [==============================] - 0s 70us/sample - loss: 0.0928 - acc: 0.9600 - val_loss: 0.1389 - val_acc: 0.9200\n",
      "Epoch 139/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.0925 - acc: 0.9700 - val_loss: 0.1297 - val_acc: 0.9200\n",
      "Epoch 140/200\n",
      "100/100 [==============================] - 0s 60us/sample - loss: 0.0885 - acc: 0.9600 - val_loss: 0.1244 - val_acc: 0.9200\n",
      "Epoch 141/200\n",
      "100/100 [==============================] - 0s 70us/sample - loss: 0.1033 - acc: 0.9400 - val_loss: 0.1198 - val_acc: 0.9200\n",
      "Epoch 142/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.0737 - acc: 0.9900 - val_loss: 0.1268 - val_acc: 0.9200\n",
      "Epoch 143/200\n",
      "100/100 [==============================] - 0s 70us/sample - loss: 0.0893 - acc: 0.9600 - val_loss: 0.1267 - val_acc: 0.9200\n",
      "Epoch 144/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.0873 - acc: 0.9700 - val_loss: 0.1239 - val_acc: 0.9200\n",
      "Epoch 145/200\n",
      "100/100 [==============================] - 0s 70us/sample - loss: 0.1244 - acc: 0.9400 - val_loss: 0.1110 - val_acc: 0.9400\n",
      "Epoch 146/200\n",
      "100/100 [==============================] - 0s 70us/sample - loss: 0.1013 - acc: 0.9400 - val_loss: 0.0838 - val_acc: 0.9600\n",
      "Epoch 147/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.0921 - acc: 0.9700 - val_loss: 0.0746 - val_acc: 0.9600\n",
      "Epoch 148/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.0774 - acc: 0.9700 - val_loss: 0.0715 - val_acc: 0.9600\n",
      "Epoch 149/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.0880 - acc: 0.9600 - val_loss: 0.0668 - val_acc: 1.0000\n",
      "Epoch 150/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.0754 - acc: 0.9700 - val_loss: 0.0569 - val_acc: 1.0000\n",
      "Epoch 151/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.0955 - acc: 0.9500 - val_loss: 0.0529 - val_acc: 1.0000\n",
      "Epoch 152/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.1144 - acc: 0.9600 - val_loss: 0.0503 - val_acc: 1.0000\n",
      "Epoch 153/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.1111 - acc: 0.9400 - val_loss: 0.0490 - val_acc: 1.0000\n",
      "Epoch 154/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.0967 - acc: 0.9500 - val_loss: 0.0455 - val_acc: 1.0000\n",
      "Epoch 155/200\n",
      "100/100 [==============================] - 0s 110us/sample - loss: 0.0830 - acc: 0.9700 - val_loss: 0.0469 - val_acc: 0.9800\n",
      "Epoch 156/200\n",
      "100/100 [==============================] - 0s 110us/sample - loss: 0.1045 - acc: 0.9600 - val_loss: 0.0489 - val_acc: 0.9800\n",
      "Epoch 157/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.0998 - acc: 0.9600 - val_loss: 0.0520 - val_acc: 0.9800\n",
      "Epoch 158/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.0758 - acc: 0.9600 - val_loss: 0.0605 - val_acc: 1.0000\n",
      "Epoch 159/200\n",
      "100/100 [==============================] - 0s 110us/sample - loss: 0.0971 - acc: 0.9600 - val_loss: 0.0761 - val_acc: 0.9600\n",
      "Epoch 160/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.1148 - acc: 0.9600 - val_loss: 0.1239 - val_acc: 0.9200\n",
      "Epoch 161/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.1116 - acc: 0.9500 - val_loss: 0.1724 - val_acc: 0.9200\n",
      "Epoch 162/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.1096 - acc: 0.9600 - val_loss: 0.2688 - val_acc: 0.8800\n",
      "Epoch 163/200\n",
      "100/100 [==============================] - 0s 110us/sample - loss: 0.1672 - acc: 0.9400 - val_loss: 0.5255 - val_acc: 0.8400\n",
      "Epoch 164/200\n",
      "100/100 [==============================] - 0s 70us/sample - loss: 0.1238 - acc: 0.9700 - val_loss: 0.5693 - val_acc: 0.8400\n",
      "Epoch 165/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.1375 - acc: 0.9400 - val_loss: 0.4386 - val_acc: 0.8400\n",
      "Epoch 166/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.0903 - acc: 0.9600 - val_loss: 0.2940 - val_acc: 0.8800\n",
      "Epoch 167/200\n",
      "100/100 [==============================] - 0s 70us/sample - loss: 0.0918 - acc: 0.9700 - val_loss: 0.2220 - val_acc: 0.9000\n",
      "Epoch 168/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.0853 - acc: 0.9700 - val_loss: 0.1928 - val_acc: 0.9200\n",
      "Epoch 169/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.0914 - acc: 0.9700 - val_loss: 0.1640 - val_acc: 0.9200\n",
      "Epoch 170/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.0910 - acc: 0.9700 - val_loss: 0.1040 - val_acc: 0.9200\n",
      "Epoch 171/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.0753 - acc: 0.9700 - val_loss: 0.0598 - val_acc: 1.0000\n",
      "Epoch 172/200\n",
      "100/100 [==============================] - 0s 70us/sample - loss: 0.0881 - acc: 0.9600 - val_loss: 0.0481 - val_acc: 1.0000\n",
      "Epoch 173/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.1576 - acc: 0.9400 - val_loss: 0.0454 - val_acc: 1.0000\n",
      "Epoch 174/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.0841 - acc: 0.9700 - val_loss: 0.0469 - val_acc: 1.0000\n",
      "Epoch 175/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.0896 - acc: 0.9600 - val_loss: 0.0526 - val_acc: 1.0000\n",
      "Epoch 176/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.1743 - acc: 0.9200 - val_loss: 0.0580 - val_acc: 1.0000\n",
      "Epoch 177/200\n",
      "100/100 [==============================] - 0s 70us/sample - loss: 0.1152 - acc: 0.9600 - val_loss: 0.0518 - val_acc: 1.0000\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 80us/sample - loss: 0.1043 - acc: 0.9400 - val_loss: 0.0490 - val_acc: 1.0000\n",
      "Epoch 179/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.0784 - acc: 0.9800 - val_loss: 0.0482 - val_acc: 1.0000\n",
      "Epoch 180/200\n",
      "100/100 [==============================] - 0s 70us/sample - loss: 0.0837 - acc: 0.9800 - val_loss: 0.0485 - val_acc: 1.0000\n",
      "Epoch 181/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.0747 - acc: 0.9800 - val_loss: 0.0475 - val_acc: 1.0000\n",
      "Epoch 182/200\n",
      "100/100 [==============================] - 0s 70us/sample - loss: 0.0922 - acc: 0.9800 - val_loss: 0.0470 - val_acc: 1.0000\n",
      "Epoch 183/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.1240 - acc: 0.9500 - val_loss: 0.0467 - val_acc: 1.0000\n",
      "Epoch 184/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.0785 - acc: 0.9700 - val_loss: 0.0458 - val_acc: 1.0000\n",
      "Epoch 185/200\n",
      "100/100 [==============================] - 0s 70us/sample - loss: 0.1676 - acc: 0.9300 - val_loss: 0.0447 - val_acc: 1.0000\n",
      "Epoch 186/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.0664 - acc: 0.9800 - val_loss: 0.0449 - val_acc: 1.0000\n",
      "Epoch 187/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.0895 - acc: 0.9700 - val_loss: 0.0453 - val_acc: 1.0000\n",
      "Epoch 188/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.0733 - acc: 0.9600 - val_loss: 0.0466 - val_acc: 1.0000\n",
      "Epoch 189/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.1119 - acc: 0.9800 - val_loss: 0.0461 - val_acc: 1.0000\n",
      "Epoch 190/200\n",
      "100/100 [==============================] - 0s 70us/sample - loss: 0.0875 - acc: 0.9700 - val_loss: 0.0452 - val_acc: 1.0000\n",
      "Epoch 191/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.1326 - acc: 0.9500 - val_loss: 0.0469 - val_acc: 1.0000\n",
      "Epoch 192/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.1050 - acc: 0.9500 - val_loss: 0.0484 - val_acc: 1.0000\n",
      "Epoch 193/200\n",
      "100/100 [==============================] - 0s 70us/sample - loss: 0.0977 - acc: 0.9600 - val_loss: 0.0475 - val_acc: 1.0000\n",
      "Epoch 194/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.1102 - acc: 0.9500 - val_loss: 0.0482 - val_acc: 1.0000\n",
      "Epoch 195/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.0800 - acc: 0.9800 - val_loss: 0.0495 - val_acc: 1.0000\n",
      "Epoch 196/200\n",
      "100/100 [==============================] - 0s 70us/sample - loss: 0.0645 - acc: 0.9900 - val_loss: 0.0512 - val_acc: 1.0000\n",
      "Epoch 197/200\n",
      "100/100 [==============================] - 0s 100us/sample - loss: 0.0892 - acc: 0.9800 - val_loss: 0.0510 - val_acc: 1.0000\n",
      "Epoch 198/200\n",
      "100/100 [==============================] - 0s 70us/sample - loss: 0.0773 - acc: 0.9600 - val_loss: 0.0503 - val_acc: 1.0000\n",
      "Epoch 199/200\n",
      "100/100 [==============================] - 0s 90us/sample - loss: 0.1020 - acc: 0.9400 - val_loss: 0.0471 - val_acc: 1.0000\n",
      "Epoch 200/200\n",
      "100/100 [==============================] - 0s 80us/sample - loss: 0.1269 - acc: 0.9500 - val_loss: 0.0423 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x165ab470>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train, batch_size=32, epochs=200,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 40us/sample - loss: 0.0690 - acc: 0.9800\n",
      "\n",
      " Accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X_train, y_train)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 312us/sample - loss: 0.0423 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04233562231063843, 1.0]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df = pd.read_csv('pima-indians-diabetes.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.63</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.35</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.67</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.17</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.29</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1   2   3    4     5     6   7  8\n",
       "0  6  148  72  35    0  33.6  0.63  50  1\n",
       "1  1   85  66  29    0  26.6  0.35  31  0\n",
       "2  8  183  64   0    0  23.3  0.67  32  1\n",
       "3  1   89  66  23   94  28.1  0.17  21  0\n",
       "4  0  137  40  35  168  43.1  2.29  33  1"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df = pre_df.sample(frac=1)\n",
    "dataset = shuffled_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,:8]\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=12, activation='relu', input_dim=8))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(units=8, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),loss='binary_crossentropy',  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/500\n",
      "576/576 [==============================] - 1s 2ms/sample - loss: 0.9901 - acc: 0.4826 - val_loss: 1.8354 - val_acc: 0.3594\n",
      "Epoch 2/500\n",
      "576/576 [==============================] - 0s 27us/sample - loss: 0.8719 - acc: 0.4913 - val_loss: 1.4621 - val_acc: 0.3646\n",
      "Epoch 3/500\n",
      "576/576 [==============================] - 0s 44us/sample - loss: 0.8037 - acc: 0.5365 - val_loss: 1.3069 - val_acc: 0.3646\n",
      "Epoch 4/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.7515 - acc: 0.5503 - val_loss: 1.2128 - val_acc: 0.3646\n",
      "Epoch 5/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.7157 - acc: 0.5972 - val_loss: 1.1359 - val_acc: 0.3646\n",
      "Epoch 6/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.6732 - acc: 0.6597 - val_loss: 1.0686 - val_acc: 0.3646\n",
      "Epoch 7/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.6529 - acc: 0.6840 - val_loss: 1.0097 - val_acc: 0.3594\n",
      "Epoch 8/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.6282 - acc: 0.7083 - val_loss: 0.9525 - val_acc: 0.3646\n",
      "Epoch 9/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.6103 - acc: 0.6962 - val_loss: 0.9034 - val_acc: 0.3698\n",
      "Epoch 10/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.6002 - acc: 0.7170 - val_loss: 0.8569 - val_acc: 0.3854\n",
      "Epoch 11/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.5915 - acc: 0.7240 - val_loss: 0.8107 - val_acc: 0.4271\n",
      "Epoch 12/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.5777 - acc: 0.7292 - val_loss: 0.7726 - val_acc: 0.4479\n",
      "Epoch 13/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.5652 - acc: 0.7396 - val_loss: 0.7368 - val_acc: 0.5312\n",
      "Epoch 14/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.5607 - acc: 0.7222 - val_loss: 0.7058 - val_acc: 0.5729\n",
      "Epoch 15/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.5627 - acc: 0.7326 - val_loss: 0.6764 - val_acc: 0.6094\n",
      "Epoch 16/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.5435 - acc: 0.7361 - val_loss: 0.6513 - val_acc: 0.6458\n",
      "Epoch 17/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.5354 - acc: 0.7483 - val_loss: 0.6245 - val_acc: 0.6823\n",
      "Epoch 18/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.5287 - acc: 0.7622 - val_loss: 0.5995 - val_acc: 0.7031\n",
      "Epoch 19/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.5275 - acc: 0.7413 - val_loss: 0.5767 - val_acc: 0.7135\n",
      "Epoch 20/500\n",
      "576/576 [==============================] - 0s 45us/sample - loss: 0.5164 - acc: 0.7517 - val_loss: 0.5597 - val_acc: 0.7292\n",
      "Epoch 21/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.5157 - acc: 0.7448 - val_loss: 0.5423 - val_acc: 0.7240\n",
      "Epoch 22/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.5060 - acc: 0.7622 - val_loss: 0.5295 - val_acc: 0.7292\n",
      "Epoch 23/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.5034 - acc: 0.7587 - val_loss: 0.5194 - val_acc: 0.7344\n",
      "Epoch 24/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4972 - acc: 0.7622 - val_loss: 0.5113 - val_acc: 0.7448\n",
      "Epoch 25/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4894 - acc: 0.7691 - val_loss: 0.5037 - val_acc: 0.7656\n",
      "Epoch 26/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.5010 - acc: 0.7830 - val_loss: 0.4976 - val_acc: 0.7708\n",
      "Epoch 27/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4864 - acc: 0.7743 - val_loss: 0.4932 - val_acc: 0.7760\n",
      "Epoch 28/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4937 - acc: 0.7778 - val_loss: 0.4897 - val_acc: 0.7708\n",
      "Epoch 29/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4792 - acc: 0.7726 - val_loss: 0.4867 - val_acc: 0.7760\n",
      "Epoch 30/500\n",
      "576/576 [==============================] - 0s 45us/sample - loss: 0.4869 - acc: 0.7674 - val_loss: 0.4840 - val_acc: 0.7656\n",
      "Epoch 31/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4980 - acc: 0.7691 - val_loss: 0.4806 - val_acc: 0.7708\n",
      "Epoch 32/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4797 - acc: 0.7795 - val_loss: 0.4796 - val_acc: 0.7656\n",
      "Epoch 33/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4743 - acc: 0.7726 - val_loss: 0.4771 - val_acc: 0.7604\n",
      "Epoch 34/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4835 - acc: 0.7656 - val_loss: 0.4771 - val_acc: 0.7604\n",
      "Epoch 35/500\n",
      "576/576 [==============================] - 0s 45us/sample - loss: 0.4836 - acc: 0.7691 - val_loss: 0.4772 - val_acc: 0.7552\n",
      "Epoch 36/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4680 - acc: 0.7899 - val_loss: 0.4751 - val_acc: 0.7552\n",
      "Epoch 37/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4792 - acc: 0.7569 - val_loss: 0.4755 - val_acc: 0.7604\n",
      "Epoch 38/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4773 - acc: 0.7743 - val_loss: 0.4766 - val_acc: 0.7656\n",
      "Epoch 39/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4717 - acc: 0.7708 - val_loss: 0.4797 - val_acc: 0.7604\n",
      "Epoch 40/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4761 - acc: 0.7708 - val_loss: 0.4811 - val_acc: 0.7604\n",
      "Epoch 41/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4609 - acc: 0.7778 - val_loss: 0.4815 - val_acc: 0.7656\n",
      "Epoch 42/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4633 - acc: 0.7847 - val_loss: 0.4808 - val_acc: 0.7708\n",
      "Epoch 43/500\n",
      "576/576 [==============================] - 0s 45us/sample - loss: 0.4644 - acc: 0.7882 - val_loss: 0.4858 - val_acc: 0.7708\n",
      "Epoch 44/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4562 - acc: 0.7951 - val_loss: 0.4898 - val_acc: 0.7448\n",
      "Epoch 45/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4514 - acc: 0.7951 - val_loss: 0.4932 - val_acc: 0.7552\n",
      "Epoch 46/500\n",
      "576/576 [==============================] - 0s 45us/sample - loss: 0.4643 - acc: 0.7865 - val_loss: 0.4853 - val_acc: 0.7760\n",
      "Epoch 47/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4610 - acc: 0.7812 - val_loss: 0.4898 - val_acc: 0.7708\n",
      "Epoch 48/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4552 - acc: 0.7899 - val_loss: 0.4901 - val_acc: 0.7500\n",
      "Epoch 49/500\n",
      "576/576 [==============================] - 0s 45us/sample - loss: 0.4653 - acc: 0.7743 - val_loss: 0.4875 - val_acc: 0.7604\n",
      "Epoch 50/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4571 - acc: 0.7830 - val_loss: 0.4833 - val_acc: 0.7708\n",
      "Epoch 51/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4687 - acc: 0.7587 - val_loss: 0.4821 - val_acc: 0.7604\n",
      "Epoch 52/500\n",
      "576/576 [==============================] - 0s 45us/sample - loss: 0.4608 - acc: 0.7882 - val_loss: 0.4798 - val_acc: 0.7500\n",
      "Epoch 53/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4502 - acc: 0.7865 - val_loss: 0.4752 - val_acc: 0.7708\n",
      "Epoch 54/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4518 - acc: 0.7795 - val_loss: 0.4738 - val_acc: 0.7708\n",
      "Epoch 55/500\n",
      "576/576 [==============================] - 0s 45us/sample - loss: 0.4486 - acc: 0.7917 - val_loss: 0.4760 - val_acc: 0.7656\n",
      "Epoch 56/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4518 - acc: 0.7934 - val_loss: 0.4738 - val_acc: 0.7604\n",
      "Epoch 57/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4582 - acc: 0.7778 - val_loss: 0.4775 - val_acc: 0.7604\n",
      "Epoch 58/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4559 - acc: 0.7917 - val_loss: 0.4768 - val_acc: 0.7656\n",
      "Epoch 59/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4600 - acc: 0.7847 - val_loss: 0.4796 - val_acc: 0.7604\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4590 - acc: 0.7708 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 61/500\n",
      "576/576 [==============================] - 0s 45us/sample - loss: 0.4532 - acc: 0.7865 - val_loss: 0.4731 - val_acc: 0.7656\n",
      "Epoch 62/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4555 - acc: 0.7726 - val_loss: 0.4748 - val_acc: 0.7656\n",
      "Epoch 63/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4411 - acc: 0.7882 - val_loss: 0.4793 - val_acc: 0.7604\n",
      "Epoch 64/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4397 - acc: 0.7882 - val_loss: 0.4786 - val_acc: 0.7552\n",
      "Epoch 65/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4525 - acc: 0.7812 - val_loss: 0.4789 - val_acc: 0.7500\n",
      "Epoch 66/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4513 - acc: 0.7951 - val_loss: 0.4777 - val_acc: 0.7552\n",
      "Epoch 67/500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4585 - acc: 0.7847 - val_loss: 0.4788 - val_acc: 0.7552\n",
      "Epoch 68/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4476 - acc: 0.7812 - val_loss: 0.4764 - val_acc: 0.7500\n",
      "Epoch 69/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4584 - acc: 0.7691 - val_loss: 0.4721 - val_acc: 0.7656\n",
      "Epoch 70/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4542 - acc: 0.7812 - val_loss: 0.4731 - val_acc: 0.7656\n",
      "Epoch 71/500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4419 - acc: 0.7986 - val_loss: 0.4727 - val_acc: 0.7604\n",
      "Epoch 72/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4496 - acc: 0.7778 - val_loss: 0.4679 - val_acc: 0.7708\n",
      "Epoch 73/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4518 - acc: 0.7795 - val_loss: 0.4756 - val_acc: 0.7656\n",
      "Epoch 74/500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4481 - acc: 0.7830 - val_loss: 0.4735 - val_acc: 0.7708\n",
      "Epoch 75/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4539 - acc: 0.7830 - val_loss: 0.4750 - val_acc: 0.7708\n",
      "Epoch 76/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4492 - acc: 0.7934 - val_loss: 0.4734 - val_acc: 0.7708\n",
      "Epoch 77/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4378 - acc: 0.7899 - val_loss: 0.4717 - val_acc: 0.7708\n",
      "Epoch 78/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4501 - acc: 0.7865 - val_loss: 0.4766 - val_acc: 0.7656\n",
      "Epoch 79/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4503 - acc: 0.7882 - val_loss: 0.4752 - val_acc: 0.7656\n",
      "Epoch 80/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4478 - acc: 0.7969 - val_loss: 0.4714 - val_acc: 0.7708\n",
      "Epoch 81/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4355 - acc: 0.7865 - val_loss: 0.4719 - val_acc: 0.7708\n",
      "Epoch 82/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4462 - acc: 0.7795 - val_loss: 0.4693 - val_acc: 0.7656\n",
      "Epoch 83/500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4416 - acc: 0.7830 - val_loss: 0.4721 - val_acc: 0.7708\n",
      "Epoch 84/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4425 - acc: 0.7899 - val_loss: 0.4761 - val_acc: 0.7656\n",
      "Epoch 85/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4455 - acc: 0.7865 - val_loss: 0.4776 - val_acc: 0.7604\n",
      "Epoch 86/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4362 - acc: 0.7882 - val_loss: 0.4727 - val_acc: 0.7708\n",
      "Epoch 87/500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4571 - acc: 0.7951 - val_loss: 0.4711 - val_acc: 0.7708\n",
      "Epoch 88/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4431 - acc: 0.7899 - val_loss: 0.4709 - val_acc: 0.7708\n",
      "Epoch 89/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4364 - acc: 0.7795 - val_loss: 0.4704 - val_acc: 0.7656\n",
      "Epoch 90/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4478 - acc: 0.8003 - val_loss: 0.4688 - val_acc: 0.7760\n",
      "Epoch 91/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4412 - acc: 0.8021 - val_loss: 0.4699 - val_acc: 0.7708\n",
      "Epoch 92/500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4494 - acc: 0.7865 - val_loss: 0.4698 - val_acc: 0.7604\n",
      "Epoch 93/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4480 - acc: 0.7934 - val_loss: 0.4732 - val_acc: 0.7656\n",
      "Epoch 94/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4422 - acc: 0.7882 - val_loss: 0.4774 - val_acc: 0.7865\n",
      "Epoch 95/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4401 - acc: 0.7917 - val_loss: 0.4716 - val_acc: 0.7708\n",
      "Epoch 96/500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4425 - acc: 0.7899 - val_loss: 0.4774 - val_acc: 0.7552\n",
      "Epoch 97/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4456 - acc: 0.7951 - val_loss: 0.4805 - val_acc: 0.7604\n",
      "Epoch 98/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4422 - acc: 0.7934 - val_loss: 0.4795 - val_acc: 0.7760\n",
      "Epoch 99/500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4435 - acc: 0.7951 - val_loss: 0.4708 - val_acc: 0.7812\n",
      "Epoch 100/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4434 - acc: 0.7882 - val_loss: 0.4706 - val_acc: 0.7656\n",
      "Epoch 101/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4328 - acc: 0.7969 - val_loss: 0.4736 - val_acc: 0.7708\n",
      "Epoch 102/500\n",
      "576/576 [==============================] - 0s 47us/sample - loss: 0.4362 - acc: 0.7778 - val_loss: 0.4720 - val_acc: 0.7656\n",
      "Epoch 103/500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4388 - acc: 0.7847 - val_loss: 0.4718 - val_acc: 0.7760\n",
      "Epoch 104/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4353 - acc: 0.7865 - val_loss: 0.4724 - val_acc: 0.7760\n",
      "Epoch 105/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4446 - acc: 0.7830 - val_loss: 0.4741 - val_acc: 0.7812\n",
      "Epoch 106/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4474 - acc: 0.7969 - val_loss: 0.4723 - val_acc: 0.7760\n",
      "Epoch 107/500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4334 - acc: 0.7934 - val_loss: 0.4729 - val_acc: 0.7760\n",
      "Epoch 108/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4333 - acc: 0.7865 - val_loss: 0.4767 - val_acc: 0.7760\n",
      "Epoch 109/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4361 - acc: 0.7986 - val_loss: 0.4793 - val_acc: 0.7708\n",
      "Epoch 110/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4296 - acc: 0.7934 - val_loss: 0.4790 - val_acc: 0.7760\n",
      "Epoch 111/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4374 - acc: 0.7969 - val_loss: 0.4824 - val_acc: 0.7656\n",
      "Epoch 112/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4377 - acc: 0.7934 - val_loss: 0.4774 - val_acc: 0.7604\n",
      "Epoch 113/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4324 - acc: 0.7934 - val_loss: 0.4796 - val_acc: 0.7760\n",
      "Epoch 114/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4391 - acc: 0.7830 - val_loss: 0.4793 - val_acc: 0.7604\n",
      "Epoch 115/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4320 - acc: 0.7951 - val_loss: 0.4802 - val_acc: 0.7656\n",
      "Epoch 116/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4343 - acc: 0.7882 - val_loss: 0.4776 - val_acc: 0.7708\n",
      "Epoch 117/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4390 - acc: 0.8038 - val_loss: 0.4745 - val_acc: 0.7656\n",
      "Epoch 118/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4460 - acc: 0.7882 - val_loss: 0.4753 - val_acc: 0.7708\n",
      "Epoch 119/500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4297 - acc: 0.7847 - val_loss: 0.4810 - val_acc: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4404 - acc: 0.7986 - val_loss: 0.4773 - val_acc: 0.7604\n",
      "Epoch 121/500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4387 - acc: 0.7847 - val_loss: 0.4755 - val_acc: 0.7500\n",
      "Epoch 122/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4253 - acc: 0.7934 - val_loss: 0.4755 - val_acc: 0.7708\n",
      "Epoch 123/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4305 - acc: 0.7917 - val_loss: 0.4750 - val_acc: 0.7604\n",
      "Epoch 124/500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4231 - acc: 0.7951 - val_loss: 0.4742 - val_acc: 0.7604\n",
      "Epoch 125/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4350 - acc: 0.7951 - val_loss: 0.4782 - val_acc: 0.7708\n",
      "Epoch 126/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4356 - acc: 0.7899 - val_loss: 0.4765 - val_acc: 0.7656\n",
      "Epoch 127/500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4439 - acc: 0.7882 - val_loss: 0.4806 - val_acc: 0.7500\n",
      "Epoch 128/500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4362 - acc: 0.8003 - val_loss: 0.4811 - val_acc: 0.7760\n",
      "Epoch 129/500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4416 - acc: 0.7882 - val_loss: 0.4802 - val_acc: 0.7500\n",
      "Epoch 130/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4233 - acc: 0.7986 - val_loss: 0.4818 - val_acc: 0.7552\n",
      "Epoch 131/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4292 - acc: 0.7951 - val_loss: 0.4791 - val_acc: 0.7552\n",
      "Epoch 132/500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4303 - acc: 0.7899 - val_loss: 0.4831 - val_acc: 0.7604\n",
      "Epoch 133/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4263 - acc: 0.8021 - val_loss: 0.4870 - val_acc: 0.7656\n",
      "Epoch 134/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4319 - acc: 0.8038 - val_loss: 0.4882 - val_acc: 0.7760\n",
      "Epoch 135/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4246 - acc: 0.8003 - val_loss: 0.4881 - val_acc: 0.7604\n",
      "Epoch 136/500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3793 - acc: 0.859 - 0s 35us/sample - loss: 0.4204 - acc: 0.8090 - val_loss: 0.4943 - val_acc: 0.7552\n",
      "Epoch 137/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4355 - acc: 0.7899 - val_loss: 0.4889 - val_acc: 0.7552\n",
      "Epoch 138/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4209 - acc: 0.7986 - val_loss: 0.4862 - val_acc: 0.7656\n",
      "Epoch 139/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4215 - acc: 0.8073 - val_loss: 0.4907 - val_acc: 0.7500\n",
      "Epoch 140/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4297 - acc: 0.7986 - val_loss: 0.4863 - val_acc: 0.7448\n",
      "Epoch 141/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4331 - acc: 0.8108 - val_loss: 0.4908 - val_acc: 0.7656\n",
      "Epoch 142/500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4289 - acc: 0.7951 - val_loss: 0.4897 - val_acc: 0.7396\n",
      "Epoch 143/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4370 - acc: 0.8003 - val_loss: 0.4832 - val_acc: 0.7604\n",
      "Epoch 144/500\n",
      "576/576 [==============================] - 0s 45us/sample - loss: 0.4312 - acc: 0.7917 - val_loss: 0.4837 - val_acc: 0.7604\n",
      "Epoch 145/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4323 - acc: 0.7934 - val_loss: 0.4830 - val_acc: 0.7500\n",
      "Epoch 146/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4211 - acc: 0.8056 - val_loss: 0.4854 - val_acc: 0.7396\n",
      "Epoch 147/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4322 - acc: 0.7969 - val_loss: 0.4908 - val_acc: 0.7292\n",
      "Epoch 148/500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4261 - acc: 0.8056 - val_loss: 0.4852 - val_acc: 0.7448\n",
      "Epoch 149/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4150 - acc: 0.8212 - val_loss: 0.4793 - val_acc: 0.7656\n",
      "Epoch 150/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4392 - acc: 0.7951 - val_loss: 0.4851 - val_acc: 0.7396\n",
      "Epoch 151/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4274 - acc: 0.8056 - val_loss: 0.4827 - val_acc: 0.7396\n",
      "Epoch 152/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4087 - acc: 0.8003 - val_loss: 0.4764 - val_acc: 0.7656\n",
      "Epoch 153/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4261 - acc: 0.7969 - val_loss: 0.4822 - val_acc: 0.7656\n",
      "Epoch 154/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4229 - acc: 0.7882 - val_loss: 0.4878 - val_acc: 0.7396\n",
      "Epoch 155/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4316 - acc: 0.7969 - val_loss: 0.4885 - val_acc: 0.7604\n",
      "Epoch 156/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4251 - acc: 0.8038 - val_loss: 0.4855 - val_acc: 0.7656\n",
      "Epoch 157/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4163 - acc: 0.8038 - val_loss: 0.4865 - val_acc: 0.7500\n",
      "Epoch 158/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4299 - acc: 0.7969 - val_loss: 0.4861 - val_acc: 0.7500\n",
      "Epoch 159/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4295 - acc: 0.7899 - val_loss: 0.4909 - val_acc: 0.7604\n",
      "Epoch 160/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4238 - acc: 0.8073 - val_loss: 0.4933 - val_acc: 0.7552\n",
      "Epoch 161/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4235 - acc: 0.8038 - val_loss: 0.4882 - val_acc: 0.7500\n",
      "Epoch 162/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4118 - acc: 0.8177 - val_loss: 0.4854 - val_acc: 0.7604\n",
      "Epoch 163/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4261 - acc: 0.7951 - val_loss: 0.4890 - val_acc: 0.7604\n",
      "Epoch 164/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4160 - acc: 0.8125 - val_loss: 0.4957 - val_acc: 0.7656\n",
      "Epoch 165/500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4149 - acc: 0.8125 - val_loss: 0.4998 - val_acc: 0.7604\n",
      "Epoch 166/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4344 - acc: 0.8003 - val_loss: 0.4975 - val_acc: 0.7500\n",
      "Epoch 167/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4079 - acc: 0.8056 - val_loss: 0.5062 - val_acc: 0.7552\n",
      "Epoch 168/500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4181 - acc: 0.8021 - val_loss: 0.5000 - val_acc: 0.7552\n",
      "Epoch 169/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4048 - acc: 0.8038 - val_loss: 0.4922 - val_acc: 0.7500\n",
      "Epoch 170/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4185 - acc: 0.8073 - val_loss: 0.4958 - val_acc: 0.7448\n",
      "Epoch 171/500\n",
      "576/576 [==============================] - 0s 45us/sample - loss: 0.4201 - acc: 0.8003 - val_loss: 0.4974 - val_acc: 0.7656\n",
      "Epoch 172/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4226 - acc: 0.8073 - val_loss: 0.4989 - val_acc: 0.7448\n",
      "Epoch 173/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4058 - acc: 0.8021 - val_loss: 0.5067 - val_acc: 0.7604\n",
      "Epoch 174/500\n",
      "576/576 [==============================] - 0s 49us/sample - loss: 0.4217 - acc: 0.8108 - val_loss: 0.5070 - val_acc: 0.7604\n",
      "Epoch 175/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4190 - acc: 0.8108 - val_loss: 0.5094 - val_acc: 0.7500\n",
      "Epoch 176/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4141 - acc: 0.7969 - val_loss: 0.5162 - val_acc: 0.7500\n",
      "Epoch 177/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4343 - acc: 0.7934 - val_loss: 0.5072 - val_acc: 0.7448\n",
      "Epoch 178/500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4089 - acc: 0.7986 - val_loss: 0.4975 - val_acc: 0.7500\n",
      "Epoch 179/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4139 - acc: 0.8056 - val_loss: 0.4965 - val_acc: 0.7344\n",
      "Epoch 180/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4085 - acc: 0.8142 - val_loss: 0.4934 - val_acc: 0.7500\n",
      "Epoch 181/500\n",
      "576/576 [==============================] - 0s 45us/sample - loss: 0.4165 - acc: 0.8125 - val_loss: 0.4968 - val_acc: 0.7604\n",
      "Epoch 182/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4241 - acc: 0.7830 - val_loss: 0.4990 - val_acc: 0.7552\n",
      "Epoch 183/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4209 - acc: 0.8021 - val_loss: 0.5011 - val_acc: 0.7396\n",
      "Epoch 184/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4099 - acc: 0.8021 - val_loss: 0.5006 - val_acc: 0.7448\n",
      "Epoch 185/500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4149 - acc: 0.8090 - val_loss: 0.4963 - val_acc: 0.7448\n",
      "Epoch 186/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4136 - acc: 0.8056 - val_loss: 0.4844 - val_acc: 0.7500\n",
      "Epoch 187/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4281 - acc: 0.8021 - val_loss: 0.4830 - val_acc: 0.7500\n",
      "Epoch 188/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4201 - acc: 0.8003 - val_loss: 0.4925 - val_acc: 0.7396\n",
      "Epoch 189/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4124 - acc: 0.8003 - val_loss: 0.4833 - val_acc: 0.7448\n",
      "Epoch 190/500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4198 - acc: 0.8194 - val_loss: 0.4826 - val_acc: 0.7448\n",
      "Epoch 191/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4052 - acc: 0.8247 - val_loss: 0.4856 - val_acc: 0.7500\n",
      "Epoch 192/500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4208 - acc: 0.8056 - val_loss: 0.4871 - val_acc: 0.7448\n",
      "Epoch 193/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4196 - acc: 0.8073 - val_loss: 0.4873 - val_acc: 0.7500\n",
      "Epoch 194/500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4292 - acc: 0.8073 - val_loss: 0.4886 - val_acc: 0.7396\n",
      "Epoch 195/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4212 - acc: 0.8003 - val_loss: 0.4835 - val_acc: 0.7500\n",
      "Epoch 196/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4108 - acc: 0.8160 - val_loss: 0.4841 - val_acc: 0.7500\n",
      "Epoch 197/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4313 - acc: 0.7934 - val_loss: 0.4893 - val_acc: 0.7500\n",
      "Epoch 198/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4096 - acc: 0.8160 - val_loss: 0.4948 - val_acc: 0.7448\n",
      "Epoch 199/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4248 - acc: 0.7969 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 200/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4013 - acc: 0.8160 - val_loss: 0.5100 - val_acc: 0.7604\n",
      "Epoch 201/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4177 - acc: 0.8177 - val_loss: 0.5218 - val_acc: 0.7656\n",
      "Epoch 202/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4111 - acc: 0.8125 - val_loss: 0.5140 - val_acc: 0.7604\n",
      "Epoch 203/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4103 - acc: 0.8212 - val_loss: 0.5115 - val_acc: 0.7604\n",
      "Epoch 204/500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4239 - acc: 0.7951 - val_loss: 0.5081 - val_acc: 0.7500\n",
      "Epoch 205/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4082 - acc: 0.8125 - val_loss: 0.5099 - val_acc: 0.7604\n",
      "Epoch 206/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4127 - acc: 0.8108 - val_loss: 0.5042 - val_acc: 0.7552\n",
      "Epoch 207/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4136 - acc: 0.8108 - val_loss: 0.5071 - val_acc: 0.7604\n",
      "Epoch 208/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4177 - acc: 0.8125 - val_loss: 0.5022 - val_acc: 0.7552\n",
      "Epoch 209/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4098 - acc: 0.8003 - val_loss: 0.4958 - val_acc: 0.7500\n",
      "Epoch 210/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4105 - acc: 0.8090 - val_loss: 0.4924 - val_acc: 0.7448\n",
      "Epoch 211/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4111 - acc: 0.8142 - val_loss: 0.4943 - val_acc: 0.7552\n",
      "Epoch 212/500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4156 - acc: 0.8056 - val_loss: 0.4929 - val_acc: 0.7344\n",
      "Epoch 213/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4112 - acc: 0.8038 - val_loss: 0.4908 - val_acc: 0.7396\n",
      "Epoch 214/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4099 - acc: 0.8142 - val_loss: 0.4964 - val_acc: 0.7500\n",
      "Epoch 215/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4186 - acc: 0.8056 - val_loss: 0.4986 - val_acc: 0.7552\n",
      "Epoch 216/500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4059 - acc: 0.8160 - val_loss: 0.5004 - val_acc: 0.7552\n",
      "Epoch 217/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4063 - acc: 0.8073 - val_loss: 0.5091 - val_acc: 0.7552\n",
      "Epoch 218/500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4267 - acc: 0.7969 - val_loss: 0.5088 - val_acc: 0.7500\n",
      "Epoch 219/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4177 - acc: 0.7969 - val_loss: 0.5168 - val_acc: 0.7604\n",
      "Epoch 220/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4070 - acc: 0.8142 - val_loss: 0.5033 - val_acc: 0.7552\n",
      "Epoch 221/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4019 - acc: 0.8194 - val_loss: 0.5012 - val_acc: 0.7656\n",
      "Epoch 222/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4105 - acc: 0.8073 - val_loss: 0.5010 - val_acc: 0.7500\n",
      "Epoch 223/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4102 - acc: 0.8090 - val_loss: 0.5024 - val_acc: 0.7396\n",
      "Epoch 224/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4046 - acc: 0.8212 - val_loss: 0.5003 - val_acc: 0.7396\n",
      "Epoch 225/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4171 - acc: 0.8003 - val_loss: 0.4973 - val_acc: 0.7448\n",
      "Epoch 226/500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4319 - acc: 0.7865 - val_loss: 0.4956 - val_acc: 0.7500\n",
      "Epoch 227/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4089 - acc: 0.8038 - val_loss: 0.4941 - val_acc: 0.7448\n",
      "Epoch 228/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4142 - acc: 0.8038 - val_loss: 0.4991 - val_acc: 0.7448\n",
      "Epoch 229/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4035 - acc: 0.8177 - val_loss: 0.4955 - val_acc: 0.7448\n",
      "Epoch 230/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4240 - acc: 0.8038 - val_loss: 0.5053 - val_acc: 0.7344\n",
      "Epoch 231/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4049 - acc: 0.8056 - val_loss: 0.5007 - val_acc: 0.7448\n",
      "Epoch 232/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4008 - acc: 0.8160 - val_loss: 0.5086 - val_acc: 0.7500\n",
      "Epoch 233/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4177 - acc: 0.8090 - val_loss: 0.5098 - val_acc: 0.7396\n",
      "Epoch 234/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4121 - acc: 0.8160 - val_loss: 0.5061 - val_acc: 0.7396\n",
      "Epoch 235/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4169 - acc: 0.8021 - val_loss: 0.5073 - val_acc: 0.7344\n",
      "Epoch 236/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4089 - acc: 0.8160 - val_loss: 0.5031 - val_acc: 0.7344\n",
      "Epoch 237/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4215 - acc: 0.7951 - val_loss: 0.5072 - val_acc: 0.7396\n",
      "Epoch 238/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4141 - acc: 0.7969 - val_loss: 0.5070 - val_acc: 0.7344\n",
      "Epoch 239/500\n",
      "576/576 [==============================] - 0s 47us/sample - loss: 0.4103 - acc: 0.7951 - val_loss: 0.5082 - val_acc: 0.7396\n",
      "Epoch 240/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4002 - acc: 0.8038 - val_loss: 0.5126 - val_acc: 0.7396\n",
      "Epoch 241/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4013 - acc: 0.8160 - val_loss: 0.5148 - val_acc: 0.7396\n",
      "Epoch 242/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4048 - acc: 0.8177 - val_loss: 0.5124 - val_acc: 0.7396\n",
      "Epoch 243/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4126 - acc: 0.7934 - val_loss: 0.5078 - val_acc: 0.7292\n",
      "Epoch 244/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4092 - acc: 0.7899 - val_loss: 0.5037 - val_acc: 0.7240\n",
      "Epoch 245/500\n",
      "576/576 [==============================] - 0s 45us/sample - loss: 0.4099 - acc: 0.8108 - val_loss: 0.5041 - val_acc: 0.7292\n",
      "Epoch 246/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4142 - acc: 0.8125 - val_loss: 0.5041 - val_acc: 0.7500\n",
      "Epoch 247/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4073 - acc: 0.8021 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 248/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4097 - acc: 0.8073 - val_loss: 0.5094 - val_acc: 0.7292\n",
      "Epoch 249/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4045 - acc: 0.8177 - val_loss: 0.5071 - val_acc: 0.7240\n",
      "Epoch 250/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4010 - acc: 0.7986 - val_loss: 0.5016 - val_acc: 0.7344\n",
      "Epoch 251/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4034 - acc: 0.8038 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 252/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4054 - acc: 0.8090 - val_loss: 0.5094 - val_acc: 0.7344\n",
      "Epoch 253/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4163 - acc: 0.7951 - val_loss: 0.5149 - val_acc: 0.7448\n",
      "Epoch 254/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4132 - acc: 0.8160 - val_loss: 0.5161 - val_acc: 0.7344\n",
      "Epoch 255/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4074 - acc: 0.8229 - val_loss: 0.5193 - val_acc: 0.7344\n",
      "Epoch 256/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.3982 - acc: 0.8177 - val_loss: 0.5135 - val_acc: 0.7344\n",
      "Epoch 257/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4070 - acc: 0.8090 - val_loss: 0.5191 - val_acc: 0.7500\n",
      "Epoch 258/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4131 - acc: 0.8038 - val_loss: 0.5242 - val_acc: 0.7448\n",
      "Epoch 259/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4048 - acc: 0.8212 - val_loss: 0.5158 - val_acc: 0.7344\n",
      "Epoch 260/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.3955 - acc: 0.8160 - val_loss: 0.5135 - val_acc: 0.7500\n",
      "Epoch 261/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.3973 - acc: 0.8281 - val_loss: 0.5202 - val_acc: 0.7500\n",
      "Epoch 262/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4118 - acc: 0.8038 - val_loss: 0.5129 - val_acc: 0.7500\n",
      "Epoch 263/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4050 - acc: 0.8108 - val_loss: 0.5051 - val_acc: 0.7500\n",
      "Epoch 264/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4124 - acc: 0.8108 - val_loss: 0.5054 - val_acc: 0.7396\n",
      "Epoch 265/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4152 - acc: 0.8021 - val_loss: 0.5071 - val_acc: 0.7448\n",
      "Epoch 266/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.3981 - acc: 0.8160 - val_loss: 0.5078 - val_acc: 0.7344\n",
      "Epoch 267/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4054 - acc: 0.8003 - val_loss: 0.5087 - val_acc: 0.7552\n",
      "Epoch 268/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4078 - acc: 0.8021 - val_loss: 0.5088 - val_acc: 0.7396\n",
      "Epoch 269/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4163 - acc: 0.7951 - val_loss: 0.5185 - val_acc: 0.7396\n",
      "Epoch 270/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4029 - acc: 0.8177 - val_loss: 0.5175 - val_acc: 0.7344\n",
      "Epoch 271/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4039 - acc: 0.8090 - val_loss: 0.5259 - val_acc: 0.7344\n",
      "Epoch 272/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4011 - acc: 0.8073 - val_loss: 0.5228 - val_acc: 0.7396\n",
      "Epoch 273/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.3957 - acc: 0.8090 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 274/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4107 - acc: 0.8125 - val_loss: 0.5085 - val_acc: 0.7604\n",
      "Epoch 275/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4181 - acc: 0.8038 - val_loss: 0.5110 - val_acc: 0.7500\n",
      "Epoch 276/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4031 - acc: 0.8160 - val_loss: 0.5111 - val_acc: 0.7240\n",
      "Epoch 277/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4050 - acc: 0.8038 - val_loss: 0.5017 - val_acc: 0.7552\n",
      "Epoch 278/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.3984 - acc: 0.8177 - val_loss: 0.5040 - val_acc: 0.7448\n",
      "Epoch 279/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4023 - acc: 0.8090 - val_loss: 0.5139 - val_acc: 0.7396\n",
      "Epoch 280/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4138 - acc: 0.8056 - val_loss: 0.5192 - val_acc: 0.7448\n",
      "Epoch 281/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.3966 - acc: 0.8073 - val_loss: 0.5211 - val_acc: 0.7448\n",
      "Epoch 282/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4046 - acc: 0.8264 - val_loss: 0.5245 - val_acc: 0.7448\n",
      "Epoch 283/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4180 - acc: 0.8056 - val_loss: 0.5250 - val_acc: 0.7448\n",
      "Epoch 284/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4094 - acc: 0.8160 - val_loss: 0.5238 - val_acc: 0.7396\n",
      "Epoch 285/500\n",
      "576/576 [==============================] - 0s 28us/sample - loss: 0.4247 - acc: 0.8021 - val_loss: 0.5361 - val_acc: 0.7552\n",
      "Epoch 286/500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4054 - acc: 0.8194 - val_loss: 0.5318 - val_acc: 0.7500\n",
      "Epoch 287/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4152 - acc: 0.8003 - val_loss: 0.5166 - val_acc: 0.7396\n",
      "Epoch 288/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4019 - acc: 0.8194 - val_loss: 0.5185 - val_acc: 0.7396\n",
      "Epoch 289/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4202 - acc: 0.8073 - val_loss: 0.5209 - val_acc: 0.7344\n",
      "Epoch 290/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4047 - acc: 0.8073 - val_loss: 0.5180 - val_acc: 0.7396\n",
      "Epoch 291/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.3965 - acc: 0.8160 - val_loss: 0.5151 - val_acc: 0.7396\n",
      "Epoch 292/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4140 - acc: 0.7951 - val_loss: 0.5151 - val_acc: 0.7396\n",
      "Epoch 293/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4053 - acc: 0.8090 - val_loss: 0.5173 - val_acc: 0.7552\n",
      "Epoch 294/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4042 - acc: 0.8194 - val_loss: 0.5204 - val_acc: 0.7396\n",
      "Epoch 295/500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4043 - acc: 0.8108 - val_loss: 0.5294 - val_acc: 0.7448\n",
      "Epoch 296/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4043 - acc: 0.8125 - val_loss: 0.5338 - val_acc: 0.7396\n",
      "Epoch 297/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4029 - acc: 0.8073 - val_loss: 0.5376 - val_acc: 0.7500\n",
      "Epoch 298/500\n",
      "576/576 [==============================] - 0s 45us/sample - loss: 0.3983 - acc: 0.8073 - val_loss: 0.5335 - val_acc: 0.7396\n",
      "Epoch 299/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4039 - acc: 0.8177 - val_loss: 0.5230 - val_acc: 0.7448\n",
      "Epoch 300/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.3999 - acc: 0.8090 - val_loss: 0.5203 - val_acc: 0.7448\n",
      "Epoch 301/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4263 - acc: 0.8212 - val_loss: 0.5133 - val_acc: 0.7292\n",
      "Epoch 302/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.3914 - acc: 0.8247 - val_loss: 0.5131 - val_acc: 0.7448\n",
      "Epoch 303/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4233 - acc: 0.8003 - val_loss: 0.5132 - val_acc: 0.7240\n",
      "Epoch 304/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.3983 - acc: 0.8247 - val_loss: 0.5212 - val_acc: 0.7396\n",
      "Epoch 305/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4062 - acc: 0.8038 - val_loss: 0.5241 - val_acc: 0.7292\n",
      "Epoch 306/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4017 - acc: 0.8194 - val_loss: 0.5214 - val_acc: 0.7344\n",
      "Epoch 307/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4009 - acc: 0.8056 - val_loss: 0.5244 - val_acc: 0.7292\n",
      "Epoch 308/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4017 - acc: 0.8073 - val_loss: 0.5232 - val_acc: 0.7292\n",
      "Epoch 309/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.3961 - acc: 0.8194 - val_loss: 0.5201 - val_acc: 0.7292\n",
      "Epoch 310/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4085 - acc: 0.8142 - val_loss: 0.5199 - val_acc: 0.7344\n",
      "Epoch 311/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4205 - acc: 0.8125 - val_loss: 0.5191 - val_acc: 0.7396\n",
      "Epoch 312/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4008 - acc: 0.8090 - val_loss: 0.5094 - val_acc: 0.7396\n",
      "Epoch 313/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4036 - acc: 0.8125 - val_loss: 0.5046 - val_acc: 0.7344\n",
      "Epoch 314/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4040 - acc: 0.8090 - val_loss: 0.5099 - val_acc: 0.7292\n",
      "Epoch 315/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4122 - acc: 0.8073 - val_loss: 0.5166 - val_acc: 0.7552\n",
      "Epoch 316/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4018 - acc: 0.8194 - val_loss: 0.5170 - val_acc: 0.7500\n",
      "Epoch 317/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4039 - acc: 0.8142 - val_loss: 0.5123 - val_acc: 0.7344\n",
      "Epoch 318/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.3958 - acc: 0.8247 - val_loss: 0.5128 - val_acc: 0.7344\n",
      "Epoch 319/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.3870 - acc: 0.8177 - val_loss: 0.5163 - val_acc: 0.7396\n",
      "Epoch 320/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4136 - acc: 0.8073 - val_loss: 0.5217 - val_acc: 0.7292\n",
      "Epoch 321/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4141 - acc: 0.8090 - val_loss: 0.5223 - val_acc: 0.7396\n",
      "Epoch 322/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3988 - acc: 0.8090 - val_loss: 0.5232 - val_acc: 0.7344\n",
      "Epoch 323/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4118 - acc: 0.8108 - val_loss: 0.5172 - val_acc: 0.7344\n",
      "Epoch 324/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4112 - acc: 0.8056 - val_loss: 0.5175 - val_acc: 0.7344\n",
      "Epoch 325/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4091 - acc: 0.8125 - val_loss: 0.5316 - val_acc: 0.7396\n",
      "Epoch 326/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4023 - acc: 0.8090 - val_loss: 0.5291 - val_acc: 0.7448\n",
      "Epoch 327/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4025 - acc: 0.8229 - val_loss: 0.5154 - val_acc: 0.7292\n",
      "Epoch 328/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.3890 - acc: 0.8212 - val_loss: 0.5228 - val_acc: 0.7448\n",
      "Epoch 329/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4013 - acc: 0.8108 - val_loss: 0.5228 - val_acc: 0.7344\n",
      "Epoch 330/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.3970 - acc: 0.8142 - val_loss: 0.5273 - val_acc: 0.7344\n",
      "Epoch 331/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4322 - acc: 0.8003 - val_loss: 0.5167 - val_acc: 0.7240\n",
      "Epoch 332/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4166 - acc: 0.8021 - val_loss: 0.5317 - val_acc: 0.7448\n",
      "Epoch 333/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4030 - acc: 0.8142 - val_loss: 0.5170 - val_acc: 0.7448\n",
      "Epoch 334/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4050 - acc: 0.8073 - val_loss: 0.5142 - val_acc: 0.7240\n",
      "Epoch 335/500\n",
      "576/576 [==============================] - 0s 47us/sample - loss: 0.4023 - acc: 0.8073 - val_loss: 0.5167 - val_acc: 0.7396\n",
      "Epoch 336/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4044 - acc: 0.8108 - val_loss: 0.5226 - val_acc: 0.7396\n",
      "Epoch 337/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.3918 - acc: 0.8125 - val_loss: 0.5456 - val_acc: 0.7292\n",
      "Epoch 338/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.3971 - acc: 0.8212 - val_loss: 0.5483 - val_acc: 0.7344\n",
      "Epoch 339/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.3956 - acc: 0.8177 - val_loss: 0.5304 - val_acc: 0.7344\n",
      "Epoch 340/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.3988 - acc: 0.8038 - val_loss: 0.5288 - val_acc: 0.7396\n",
      "Epoch 341/500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4050 - acc: 0.8125 - val_loss: 0.5302 - val_acc: 0.7344\n",
      "Epoch 342/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4026 - acc: 0.8090 - val_loss: 0.5391 - val_acc: 0.7344\n",
      "Epoch 343/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.3994 - acc: 0.8003 - val_loss: 0.5434 - val_acc: 0.7292\n",
      "Epoch 344/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4002 - acc: 0.7969 - val_loss: 0.5349 - val_acc: 0.7240\n",
      "Epoch 345/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.3946 - acc: 0.8125 - val_loss: 0.5472 - val_acc: 0.7396\n",
      "Epoch 346/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4026 - acc: 0.8003 - val_loss: 0.5423 - val_acc: 0.7396\n",
      "Epoch 347/500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4088 - acc: 0.8038 - val_loss: 0.5365 - val_acc: 0.7344\n",
      "Epoch 348/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4095 - acc: 0.8056 - val_loss: 0.5346 - val_acc: 0.7396\n",
      "Epoch 349/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.3960 - acc: 0.8125 - val_loss: 0.5265 - val_acc: 0.7292\n",
      "Epoch 350/500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.3978 - acc: 0.8108 - val_loss: 0.5256 - val_acc: 0.7292\n",
      "Epoch 351/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4041 - acc: 0.8056 - val_loss: 0.5350 - val_acc: 0.7396\n",
      "Epoch 352/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4024 - acc: 0.8212 - val_loss: 0.5273 - val_acc: 0.7344\n",
      "Epoch 353/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.3986 - acc: 0.8021 - val_loss: 0.5246 - val_acc: 0.7292\n",
      "Epoch 354/500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4025 - acc: 0.8194 - val_loss: 0.5302 - val_acc: 0.7344\n",
      "Epoch 355/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4069 - acc: 0.8003 - val_loss: 0.5287 - val_acc: 0.7344\n",
      "Epoch 356/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 40us/sample - loss: 0.3836 - acc: 0.8108 - val_loss: 0.5314 - val_acc: 0.7292\n",
      "Epoch 357/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4034 - acc: 0.8160 - val_loss: 0.5369 - val_acc: 0.7344\n",
      "Epoch 358/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4103 - acc: 0.8090 - val_loss: 0.5381 - val_acc: 0.7344\n",
      "Epoch 359/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4193 - acc: 0.8160 - val_loss: 0.5274 - val_acc: 0.7188\n",
      "Epoch 360/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.3964 - acc: 0.8125 - val_loss: 0.5242 - val_acc: 0.7396\n",
      "Epoch 361/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4098 - acc: 0.8108 - val_loss: 0.5238 - val_acc: 0.7448\n",
      "Epoch 362/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4060 - acc: 0.7969 - val_loss: 0.5269 - val_acc: 0.7344\n",
      "Epoch 363/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3962 - acc: 0.8229 - val_loss: 0.5324 - val_acc: 0.7292\n",
      "Epoch 364/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4059 - acc: 0.8177 - val_loss: 0.5350 - val_acc: 0.7552\n",
      "Epoch 365/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4106 - acc: 0.8056 - val_loss: 0.5298 - val_acc: 0.7500\n",
      "Epoch 366/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.3962 - acc: 0.8177 - val_loss: 0.5227 - val_acc: 0.7292\n",
      "Epoch 367/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4122 - acc: 0.8038 - val_loss: 0.5228 - val_acc: 0.7292\n",
      "Epoch 368/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4106 - acc: 0.8038 - val_loss: 0.5195 - val_acc: 0.7292\n",
      "Epoch 369/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.3855 - acc: 0.8142 - val_loss: 0.5297 - val_acc: 0.7344\n",
      "Epoch 370/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.3893 - acc: 0.8368 - val_loss: 0.5353 - val_acc: 0.7292\n",
      "Epoch 371/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.3986 - acc: 0.8003 - val_loss: 0.5276 - val_acc: 0.7344\n",
      "Epoch 372/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3954 - acc: 0.8281 - val_loss: 0.5138 - val_acc: 0.7396\n",
      "Epoch 373/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3963 - acc: 0.8108 - val_loss: 0.5110 - val_acc: 0.7396\n",
      "Epoch 374/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3848 - acc: 0.8299 - val_loss: 0.5240 - val_acc: 0.7292\n",
      "Epoch 375/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.3943 - acc: 0.8038 - val_loss: 0.5535 - val_acc: 0.7292\n",
      "Epoch 376/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4144 - acc: 0.7986 - val_loss: 0.5360 - val_acc: 0.7344\n",
      "Epoch 377/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4076 - acc: 0.7951 - val_loss: 0.5381 - val_acc: 0.7344\n",
      "Epoch 378/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3964 - acc: 0.8160 - val_loss: 0.5343 - val_acc: 0.7292\n",
      "Epoch 379/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4009 - acc: 0.8056 - val_loss: 0.5324 - val_acc: 0.7240\n",
      "Epoch 380/500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4007 - acc: 0.8194 - val_loss: 0.5322 - val_acc: 0.7292\n",
      "Epoch 381/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.3789 - acc: 0.8247 - val_loss: 0.5344 - val_acc: 0.7292\n",
      "Epoch 382/500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4017 - acc: 0.7951 - val_loss: 0.5297 - val_acc: 0.7240\n",
      "Epoch 383/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.3903 - acc: 0.8247 - val_loss: 0.5256 - val_acc: 0.7344\n",
      "Epoch 384/500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.3859 - acc: 0.8247 - val_loss: 0.5177 - val_acc: 0.7396\n",
      "Epoch 385/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3992 - acc: 0.8177 - val_loss: 0.5160 - val_acc: 0.7240\n",
      "Epoch 386/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4023 - acc: 0.8212 - val_loss: 0.5135 - val_acc: 0.7448\n",
      "Epoch 387/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4141 - acc: 0.8038 - val_loss: 0.5076 - val_acc: 0.7292\n",
      "Epoch 388/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.3946 - acc: 0.8125 - val_loss: 0.5092 - val_acc: 0.7292\n",
      "Epoch 389/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3963 - acc: 0.8229 - val_loss: 0.5152 - val_acc: 0.7448\n",
      "Epoch 390/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.3934 - acc: 0.8125 - val_loss: 0.5055 - val_acc: 0.7396\n",
      "Epoch 391/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3918 - acc: 0.8142 - val_loss: 0.5102 - val_acc: 0.7292\n",
      "Epoch 392/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.3992 - acc: 0.8108 - val_loss: 0.5157 - val_acc: 0.7240\n",
      "Epoch 393/500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4052 - acc: 0.8125 - val_loss: 0.5181 - val_acc: 0.7344\n",
      "Epoch 394/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.3982 - acc: 0.8090 - val_loss: 0.5185 - val_acc: 0.7292\n",
      "Epoch 395/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4069 - acc: 0.8056 - val_loss: 0.5402 - val_acc: 0.7292\n",
      "Epoch 396/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4018 - acc: 0.8142 - val_loss: 0.5351 - val_acc: 0.7344\n",
      "Epoch 397/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4097 - acc: 0.8108 - val_loss: 0.5344 - val_acc: 0.7240\n",
      "Epoch 398/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.3848 - acc: 0.8194 - val_loss: 0.5250 - val_acc: 0.7240\n",
      "Epoch 399/500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4070 - acc: 0.8038 - val_loss: 0.5366 - val_acc: 0.7344\n",
      "Epoch 400/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4100 - acc: 0.8212 - val_loss: 0.5386 - val_acc: 0.7240\n",
      "Epoch 401/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4030 - acc: 0.8125 - val_loss: 0.5435 - val_acc: 0.7396\n",
      "Epoch 402/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4147 - acc: 0.7969 - val_loss: 0.5261 - val_acc: 0.7292\n",
      "Epoch 403/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4029 - acc: 0.8125 - val_loss: 0.5208 - val_acc: 0.7448\n",
      "Epoch 404/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4087 - acc: 0.8073 - val_loss: 0.5138 - val_acc: 0.7448\n",
      "Epoch 405/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4095 - acc: 0.8021 - val_loss: 0.5127 - val_acc: 0.7396\n",
      "Epoch 406/500\n",
      "576/576 [==============================] - 0s 45us/sample - loss: 0.3945 - acc: 0.8142 - val_loss: 0.5123 - val_acc: 0.7240\n",
      "Epoch 407/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.4011 - acc: 0.8003 - val_loss: 0.5243 - val_acc: 0.7292\n",
      "Epoch 408/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4033 - acc: 0.8003 - val_loss: 0.5208 - val_acc: 0.7292\n",
      "Epoch 409/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4061 - acc: 0.8056 - val_loss: 0.5201 - val_acc: 0.7448\n",
      "Epoch 410/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3872 - acc: 0.8177 - val_loss: 0.5146 - val_acc: 0.7292\n",
      "Epoch 411/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.3984 - acc: 0.8160 - val_loss: 0.5090 - val_acc: 0.7344\n",
      "Epoch 412/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4085 - acc: 0.8160 - val_loss: 0.5014 - val_acc: 0.7448\n",
      "Epoch 413/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.3886 - acc: 0.8125 - val_loss: 0.5009 - val_acc: 0.7448\n",
      "Epoch 414/500\n",
      "576/576 [==============================] - 0s 47us/sample - loss: 0.4052 - acc: 0.8142 - val_loss: 0.5066 - val_acc: 0.7448\n",
      "Epoch 415/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 52us/sample - loss: 0.3928 - acc: 0.8073 - val_loss: 0.5108 - val_acc: 0.7448\n",
      "Epoch 416/500\n",
      "576/576 [==============================] - 0s 47us/sample - loss: 0.3991 - acc: 0.8038 - val_loss: 0.5130 - val_acc: 0.7344\n",
      "Epoch 417/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.3973 - acc: 0.8038 - val_loss: 0.5145 - val_acc: 0.7292\n",
      "Epoch 418/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.3924 - acc: 0.8229 - val_loss: 0.5236 - val_acc: 0.7344\n",
      "Epoch 419/500\n",
      "576/576 [==============================] - 0s 45us/sample - loss: 0.3940 - acc: 0.8247 - val_loss: 0.5186 - val_acc: 0.7500\n",
      "Epoch 420/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4077 - acc: 0.8021 - val_loss: 0.5144 - val_acc: 0.7500\n",
      "Epoch 421/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.3899 - acc: 0.8160 - val_loss: 0.5183 - val_acc: 0.7240\n",
      "Epoch 422/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4051 - acc: 0.8003 - val_loss: 0.5345 - val_acc: 0.7292\n",
      "Epoch 423/500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4000 - acc: 0.8003 - val_loss: 0.5229 - val_acc: 0.7188\n",
      "Epoch 424/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.3945 - acc: 0.8038 - val_loss: 0.5291 - val_acc: 0.7448\n",
      "Epoch 425/500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3722 - acc: 0.859 - 0s 38us/sample - loss: 0.3845 - acc: 0.8212 - val_loss: 0.5232 - val_acc: 0.7396\n",
      "Epoch 426/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4152 - acc: 0.8038 - val_loss: 0.5177 - val_acc: 0.7292\n",
      "Epoch 427/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3895 - acc: 0.8142 - val_loss: 0.5162 - val_acc: 0.7292\n",
      "Epoch 428/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3902 - acc: 0.8108 - val_loss: 0.5217 - val_acc: 0.7396\n",
      "Epoch 429/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3975 - acc: 0.8194 - val_loss: 0.5318 - val_acc: 0.7292\n",
      "Epoch 430/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4010 - acc: 0.8073 - val_loss: 0.5445 - val_acc: 0.7344\n",
      "Epoch 431/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.3876 - acc: 0.8177 - val_loss: 0.5464 - val_acc: 0.7240\n",
      "Epoch 432/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3977 - acc: 0.8160 - val_loss: 0.5498 - val_acc: 0.7292\n",
      "Epoch 433/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4038 - acc: 0.7951 - val_loss: 0.5395 - val_acc: 0.7292\n",
      "Epoch 434/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3873 - acc: 0.8160 - val_loss: 0.5495 - val_acc: 0.7448\n",
      "Epoch 435/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3961 - acc: 0.8194 - val_loss: 0.5324 - val_acc: 0.7292\n",
      "Epoch 436/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3837 - acc: 0.8212 - val_loss: 0.5247 - val_acc: 0.7344\n",
      "Epoch 437/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3873 - acc: 0.8229 - val_loss: 0.5289 - val_acc: 0.7344\n",
      "Epoch 438/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3835 - acc: 0.8125 - val_loss: 0.5354 - val_acc: 0.7344\n",
      "Epoch 439/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.3987 - acc: 0.8125 - val_loss: 0.5393 - val_acc: 0.7344\n",
      "Epoch 440/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.3898 - acc: 0.8056 - val_loss: 0.5355 - val_acc: 0.7396\n",
      "Epoch 441/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.3886 - acc: 0.8056 - val_loss: 0.5373 - val_acc: 0.7344\n",
      "Epoch 442/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3970 - acc: 0.8142 - val_loss: 0.5309 - val_acc: 0.7344\n",
      "Epoch 443/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.4003 - acc: 0.8038 - val_loss: 0.5266 - val_acc: 0.7344\n",
      "Epoch 444/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.3988 - acc: 0.8056 - val_loss: 0.5306 - val_acc: 0.7344\n",
      "Epoch 445/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.3893 - acc: 0.8125 - val_loss: 0.5300 - val_acc: 0.7344\n",
      "Epoch 446/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3968 - acc: 0.8160 - val_loss: 0.5401 - val_acc: 0.7396\n",
      "Epoch 447/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.3988 - acc: 0.8108 - val_loss: 0.5427 - val_acc: 0.7240\n",
      "Epoch 448/500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.3922 - acc: 0.8229 - val_loss: 0.5286 - val_acc: 0.7240\n",
      "Epoch 449/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3865 - acc: 0.8247 - val_loss: 0.5275 - val_acc: 0.7292\n",
      "Epoch 450/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.3917 - acc: 0.8160 - val_loss: 0.5353 - val_acc: 0.7344\n",
      "Epoch 451/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.3850 - acc: 0.8194 - val_loss: 0.5387 - val_acc: 0.7344\n",
      "Epoch 452/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.3978 - acc: 0.8108 - val_loss: 0.5664 - val_acc: 0.7396\n",
      "Epoch 453/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.3897 - acc: 0.8177 - val_loss: 0.5572 - val_acc: 0.7292\n",
      "Epoch 454/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.4001 - acc: 0.8194 - val_loss: 0.5295 - val_acc: 0.7396\n",
      "Epoch 455/500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.3972 - acc: 0.8038 - val_loss: 0.5276 - val_acc: 0.7292\n",
      "Epoch 456/500\n",
      "576/576 [==============================] - 0s 45us/sample - loss: 0.3975 - acc: 0.8021 - val_loss: 0.5387 - val_acc: 0.7240\n",
      "Epoch 457/500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.4036 - acc: 0.8108 - val_loss: 0.5456 - val_acc: 0.7292\n",
      "Epoch 458/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4026 - acc: 0.8021 - val_loss: 0.5392 - val_acc: 0.7240\n",
      "Epoch 459/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.3935 - acc: 0.7934 - val_loss: 0.5293 - val_acc: 0.7188\n",
      "Epoch 460/500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.3943 - acc: 0.8194 - val_loss: 0.5322 - val_acc: 0.7448\n",
      "Epoch 461/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3923 - acc: 0.8177 - val_loss: 0.5324 - val_acc: 0.7396\n",
      "Epoch 462/500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.3892 - acc: 0.8247 - val_loss: 0.5423 - val_acc: 0.7188\n",
      "Epoch 463/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.3931 - acc: 0.8073 - val_loss: 0.5469 - val_acc: 0.7240\n",
      "Epoch 464/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3908 - acc: 0.8108 - val_loss: 0.5657 - val_acc: 0.7292\n",
      "Epoch 465/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3780 - acc: 0.8108 - val_loss: 0.5490 - val_acc: 0.7292\n",
      "Epoch 466/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3949 - acc: 0.8229 - val_loss: 0.5512 - val_acc: 0.7344\n",
      "Epoch 467/500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.3957 - acc: 0.8247 - val_loss: 0.5551 - val_acc: 0.7292\n",
      "Epoch 468/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4036 - acc: 0.8003 - val_loss: 0.5510 - val_acc: 0.7344\n",
      "Epoch 469/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.3992 - acc: 0.8108 - val_loss: 0.5547 - val_acc: 0.7396\n",
      "Epoch 470/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3994 - acc: 0.8229 - val_loss: 0.5636 - val_acc: 0.7448\n",
      "Epoch 471/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.4039 - acc: 0.8021 - val_loss: 0.5701 - val_acc: 0.7344\n",
      "Epoch 472/500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.3965 - acc: 0.8177 - val_loss: 0.5674 - val_acc: 0.7188\n",
      "Epoch 473/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.3957 - acc: 0.8177 - val_loss: 0.5628 - val_acc: 0.7344\n",
      "Epoch 474/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 33us/sample - loss: 0.4056 - acc: 0.8021 - val_loss: 0.5706 - val_acc: 0.7396\n",
      "Epoch 475/500\n",
      "576/576 [==============================] - 0s 33us/sample - loss: 0.3862 - acc: 0.8125 - val_loss: 0.5767 - val_acc: 0.7448\n",
      "Epoch 476/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.3848 - acc: 0.8125 - val_loss: 0.5853 - val_acc: 0.7344\n",
      "Epoch 477/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3815 - acc: 0.8177 - val_loss: 0.5981 - val_acc: 0.7396\n",
      "Epoch 478/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3969 - acc: 0.8229 - val_loss: 0.6089 - val_acc: 0.7344\n",
      "Epoch 479/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.4037 - acc: 0.8073 - val_loss: 0.6233 - val_acc: 0.7344\n",
      "Epoch 480/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3842 - acc: 0.8194 - val_loss: 0.6177 - val_acc: 0.7240\n",
      "Epoch 481/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.3842 - acc: 0.8229 - val_loss: 0.6176 - val_acc: 0.7240\n",
      "Epoch 482/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.4138 - acc: 0.7917 - val_loss: 0.6154 - val_acc: 0.7292\n",
      "Epoch 483/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3774 - acc: 0.8299 - val_loss: 0.6282 - val_acc: 0.7188\n",
      "Epoch 484/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3963 - acc: 0.8038 - val_loss: 0.6372 - val_acc: 0.7240\n",
      "Epoch 485/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.3989 - acc: 0.8003 - val_loss: 0.6270 - val_acc: 0.7344\n",
      "Epoch 486/500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.3996 - acc: 0.8108 - val_loss: 0.6297 - val_acc: 0.7292\n",
      "Epoch 487/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.3882 - acc: 0.8160 - val_loss: 0.6383 - val_acc: 0.7396\n",
      "Epoch 488/500\n",
      "576/576 [==============================] - 0s 35us/sample - loss: 0.3803 - acc: 0.8177 - val_loss: 0.6459 - val_acc: 0.7135\n",
      "Epoch 489/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.3858 - acc: 0.8212 - val_loss: 0.6389 - val_acc: 0.7240\n",
      "Epoch 490/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.3898 - acc: 0.8177 - val_loss: 0.6356 - val_acc: 0.7135\n",
      "Epoch 491/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.3816 - acc: 0.8160 - val_loss: 0.6461 - val_acc: 0.7188\n",
      "Epoch 492/500\n",
      "576/576 [==============================] - 0s 31us/sample - loss: 0.3909 - acc: 0.8160 - val_loss: 0.6608 - val_acc: 0.7240\n",
      "Epoch 493/500\n",
      "576/576 [==============================] - 0s 42us/sample - loss: 0.3951 - acc: 0.8003 - val_loss: 0.6508 - val_acc: 0.7240\n",
      "Epoch 494/500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.4038 - acc: 0.8108 - val_loss: 0.6429 - val_acc: 0.7344\n",
      "Epoch 495/500\n",
      "576/576 [==============================] - 0s 38us/sample - loss: 0.3940 - acc: 0.8142 - val_loss: 0.6401 - val_acc: 0.7344\n",
      "Epoch 496/500\n",
      "576/576 [==============================] - 0s 40us/sample - loss: 0.3893 - acc: 0.8125 - val_loss: 0.6323 - val_acc: 0.7396\n",
      "Epoch 497/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.3896 - acc: 0.8073 - val_loss: 0.6371 - val_acc: 0.7292\n",
      "Epoch 498/500\n",
      "576/576 [==============================] - 0s 43us/sample - loss: 0.3891 - acc: 0.8090 - val_loss: 0.6398 - val_acc: 0.7292\n",
      "Epoch 499/500\n",
      "576/576 [==============================] - 0s 30us/sample - loss: 0.3994 - acc: 0.8090 - val_loss: 0.6506 - val_acc: 0.7396\n",
      "Epoch 500/500\n",
      "576/576 [==============================] - 0s 36us/sample - loss: 0.3864 - acc: 0.8160 - val_loss: 0.6529 - val_acc: 0.7240\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x=X_train,y=y_train, batch_size=64, epochs=500,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "\n",
    "lines, labels = loss_ax.get_legend_handles_labels()\n",
    "lines2, labels2 = acc_ax.get_legend_handles_labels()\n",
    "acc_ax.legend(lines + lines2, labels + labels2, loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 [==============================] - 0s 120us/sample - loss: 0.6529 - acc: 0.7240\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dataset의 loss는 0.6529422501722971, accuracy는 0.7239583134651184\n"
     ]
    }
   ],
   "source": [
    "print('test dataset의 loss는 {}, accuracy는 {}'.format(loss,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
